[
  {
    "objectID": "Lesson04_Regression.html",
    "href": "Lesson04_Regression.html",
    "title": "Lesson 4: regression",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 8",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#introduction",
    "href": "Lesson04_Regression.html#introduction",
    "title": "Lesson 4: regression",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nWe’re moving on to simple linear regression. The model that underlies that analysis is no different than for the t-test, except that now the explanatory variable is continuous rather than an indicator variable. We will also encounter goodness-of-fit (GOF) testing, making predictions, and interpreting confidence and credible intervals. As a reminder, the model we are working with is\n\\(y_i = \\alpha + \\beta \\times x_i + \\epsilon_i\\)\n\\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)\nInterpretation: \\(\\alpha\\) is the y-intercept of the line, and \\(\\beta\\) is the slope.\nKéry (2010) uses as an example for this chapter data collected from Swiss surveys of a bird called the wallcreeper, a species that has been declining in abundance in recent years. We’ll assume that were collect over years 1990-2005 from a sample of quadrats where the species was observed. We’ll further assume that deviations from a linear trend are normally distributed.",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#data-simulation",
    "href": "Lesson04_Regression.html#data-simulation",
    "title": "Lesson 4: regression",
    "section": "4.2 Data simulation",
    "text": "4.2 Data simulation\nBased on this scenario in mind, let’s simulate some data:\nn &lt;- 16                 # Number of years\na = 40                  # Intercept\nb = -1.5                # Slope\nsigma2 = 25             # Residual variance\n\nx &lt;- 1:16               # Values of covariate year\neps &lt;- rnorm(n, mean = 0, sd = sqrt(sigma2))\ny &lt;- a + b*x + eps          # Assemble data set\n\nggplot() +\n  geom_point(aes(x = (x+1989), y = y)) +\n  xlab('Year') +\n  ylab('Prop. occupied (%)')",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#classical-analysis-in-r",
    "href": "Lesson04_Regression.html#classical-analysis-in-r",
    "title": "Lesson 4: regression",
    "section": "4.3 Classical analysis in R",
    "text": "4.3 Classical analysis in R\nout0 &lt;- lm(y ~ I(x+1989))\nsummary(out0)\n\nggplot() +\n  geom_point(aes(x = (x+1989), y = y)) +\n  geom_abline(intercept = out0$coefficients[1], slope = out0$coefficients[2],\n              colour = 'blue') +\n  xlab('Year') +\n  ylab('Prop. occupied (%)')",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#bayesian-analysis-with-bugs",
    "href": "Lesson04_Regression.html#bayesian-analysis-with-bugs",
    "title": "Lesson 4: regression",
    "section": "4.4 Bayesian analysis with BUGS",
    "text": "4.4 Bayesian analysis with BUGS\nWe’ll now use the same model to conduct a Bayesian analysis. We will also incorporate posterior predictive checking and Bayesian p-values to assess model GOF. Remember to load the \\({\\tt nimble}\\) library.\n \n\n4.4.1 Fitting the model\n# specify the model\nmodel.lregr &lt;- nimbleCode({\n  \n  # Priors\n  alpha ~ dnorm(0, sd = 30)\n  beta ~ dnorm(0, sd = 30)\n  sigma ~ dunif(0, 100)\n  \n  # Likelihood\n  for (i in 1:n){\n    y[i] ~ dnorm(mu[i], sd = sigma)\n    mu[i] &lt;- alpha + beta*x[i]\n  }\n  \n  # Derived quantities\n  p.decline &lt;- 1-step(beta)     # Probability of decline\n  \n  # Assess model fit using a sums-of-squares-type discrepancy\n  for (i in 1:n) {\n    residual[i] &lt;- y[i] - mu[i]     # Residuals for observed data\n    predicted[i] &lt;- mu[i]       # Predicted values\n    sq[i] &lt;- residual[i]^2  # Squared residuals for observed data\n    \n    # Generate replicate data and compute fit stats for them\n    y.new[i] ~ dnorm(mu[i], sd = sigma) # one new data set at each MCMC iteration\n    sq.new[i] &lt;- (y.new[i] - predicted[i])^2    # Squared residuals for new data\n  }\n  \n  fit &lt;- sum(sq[])          # Sum of squared residuals for actual data set\n  fit.new &lt;- sum(sq.new[])      # Sum of squared residuals for new data set\n})\n\n# data and constants\nmy.data &lt;- list(x = x, y = y)\nmy.consts &lt;- list(n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(1), beta = rnorm(1),\n                            sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha','beta', 'p.decline', 'sigma', 'fit', 'fit.new',\n               'residual', 'predicted')\n\n# MCMC settings\nnc &lt;- 3     # no. chains\nni &lt;- 1200  # no. draws from posterior for each chain\nnb &lt;- 200   # no. draws to discard as burn in\nnt &lt;- 1     # thinning rate\n\n# start Gibbs sampler\nout1 &lt;- nimbleMCMC(code = model.lregr,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc,\n                   dimensions = list(sq = c(n), sq.new = c(n)))\n\n# the dimensions setting: for some quantities created inside a model, NIMBLE\n# wants the dimensions specified. Both sq and sq.new will have n values\n# in them.\n\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\n \n\n\n4.4.2 Goodness of fit assessment in Bayesian analysis\nThere are two parts to the BUGS code that assess GOF for our model.\n\nTwo lines that compute residuals and predicted values under the model.\nCode that computes a Bayesian p-value.\n\nWe’ll assess GOF for this model using two approaches: a residual check typical for regression analyses and a posterior predictive check using Bayesian p-values.\n \n\nResidual plots\nAn easy way to check GOF is to look at plots of the residuals. For the normal linear regression model, we assume residuals are normally-distributed with a constant variance. Violation of this homoscedacity assumption means that there is some pattern evident in the residuals. Plotting the residuals against predicted values reveals no evidence of a pattern.\nggplot() +\n  geom_point(aes(x = outSum1$mean[6:21], y = outSum1$mean[22:37])) +\n  geom_hline(yintercept = 0) +\n  xlab('Predicted values') +\n  ylab('Residuals')\n \n\n\nPosterior predictive checks\nUsing Bayesian p-values to check the posterior predictive distribution is a general way to assess GOF when fitting a model using MCMC. The idea is that we generate an ideal data set based on the model, which should in principle fit the model perfectly and conform to whatever assumptions are inherent in the model. We then compare those generated data to our observed data to see how well they correspond. Unlike for classical analysis, where GOF testing generates a single value (e.g. a \\(\\chi^2\\) value), in Bayesian we once again have a distribution for any calculated value, based on the values of the Markov chains. This is the same for a GOF statistic. This is something we’ll see again and again in Bayesian analysis.\nHow do we calculate a Bayesian p-value? First we must decide on a discrepancy measure, something that measure the difference between observed and ideal values. Chi-square goodness-of-fit is one such measure. Another is a sum-of-squares type of measure, which we will use below. We apply the measure to the ideal data, and to the observed data, and we judge how often one measure is larger than the other. For a good-fitting model, we should get the ideal data having better fit about half the time (i.e \\(p = 0.5\\)). A value closer to 0 or 1 indicates poor fit. In addition to calculating the Bayesian p-value itself, we can also use a graphical posterior predictive check. We do both here:\n# extract fit and fit.new from the Markov chains\nfit_samples &lt;- c(out1$chain1[,'fit'],\n                 out1$chain2[,'fit'],\n                 out1$chain3[,'fit'])\n\nfitnew_samples &lt;- c(out1$chain1[,'fit.new'],\n                    out1$chain2[,'fit.new'],\n                    out1$chain3[,'fit.new'])\n\nggplot() +\n  geom_point(aes(x = fit_samples, y = fitnew_samples)) +\n  geom_abline(intercept = 0, slope = 1) +\n  xlim(0, 3200) +\n  ylim(0, 3200) +\n  xlab('SSQ for actual data set') +\n  ylab('SSQ for ideal (new) data sets')\n## Warning: Removed 4 rows containing missing values or values outside the scale range\n## (`geom_point()`).\nmean(fitnew_samples &gt; fit_samples)  # Bayesian p-value\nGiven that our data came from a simulated process based on this model, there’s no surprise that model fit appears adequate. Some statisticians believe that posterior predictive checks are too liberal (more likely to conclude adequate fit when there really isn’t), because the same data are used both to generate the replicate data and then to compare them to these replicates.\n \n\n\n\n4.4.3 Making predictions\nWhen we make a prediction we are using a model to infer an expected value of the response variable for some hypothetical value of the explanatory variables. Why is this important?\n\nPredictions, particularly via graphs, are effective ways of communicating what can be learned from the model.\nEspecially for complex models, when there are polynomial terms, interactions, or Poisson or binomial responses, predictions might be the only way for us to understand a model.\n\nFor simple regression like in this chapter, we can visualise the model just from the parameter estimates (the slope and intercept). For practice, let’s make some predictions based on the models from this lesson.\nA plot of the models (classical and Bayesian):\n# predicted values from Bayesian analysis\npred.y &lt;- outSum1['alpha', 'mean'] + outSum1['beta', 'mean'] * x\nx &lt;- 1989 + x # year variable\n\nggplot() +\n  geom_point(aes(x = x, y = y)) +\n  geom_smooth(mapping = aes(x = x, y = y),\n              method = lm, se = F, colour = 'blue') + # predicted from classical\n  geom_smooth(mapping = aes(x = x, y = pred.y),\n              method = lm, se = F, colour = 'red') +\n  xlab('Year') +\n  ylab('Prop. occupied (%)')\nObserved (black dots) and predicted change in occurrence of Swiss wallcreepers (blue: classical analysis; red: Bayesian analysis). Because the two lines overlap quite closely we can see that we get very similar inferences under the two paradigms.\nMaking inferences also includes the degree of uncertainty in our estimates. Like in classical analysis, in Bayesian we can calculate intervals to demonstrate the uncertainty in two ways: (1) intervals based on observed data (i.e. credible intervals) and (2) intervals based on a new sample from the same population (i.e. prediction interval). We would expect the intervals for (2) to be wider because of the added uncertainty associated with collecting a new sample. Here is an example of a credible interval\nWe start by computing the expected response from estimated \\(\\alpha\\) and \\(\\beta\\) for each year of the study. Then we use the 2.5th and 97.5th percentiles on the bounds of the posterior distribution as the credible interval limits.\n# extract alphas and betas from the Markov chains\nalpha.samples &lt;- c(out1$chain1[,'alpha'],\n                   out1$chain2[,'alpha'],\n                   out1$chain3[,'alpha'])\n\nbeta.samples &lt;- c(out1$chain1[,'beta'],\n                  out1$chain2[,'beta'],\n                  out1$chain3[,'beta'])\n\n# create an array to hold predictions\npredictions &lt;- array(dim = c(length(x), length(alpha.samples)))\n\n# calculate predictions\nfor(i in 1:length(x)){\n   predictions[i,] &lt;- alpha.samples + beta.samples*i\n}\n\nLPB &lt;- apply(predictions, 1, quantile, probs = 0.025) # Lower bound\nUPB &lt;- apply(predictions, 1, quantile, probs = 0.975) # Upper bound\n\n# graph data, best-fit line and credible intervals\nggplot() +\n  geom_point(aes(x = x, y = y)) +\n  geom_smooth(mapping = aes(x = x, y = pred.y), method = lm, se = F,\n              colour = 'black') +\n  geom_smooth(mapping = aes(x = x, y = LPB), method = loess, se = F,\n              colour = 'grey') +\n  geom_smooth(mapping = aes(x = x, y = UPB), method = loess, se = F,\n              colour = 'grey') +\n  xlab('Year') +\n  ylab('Prop. occupied (%)')\n \n\n\n4.4.4 Confidence versus credible intervals\nHow does the interpretation differ between confidence and credible intervals?\nUnder the classical paradigm, we could take an estimate of the slope ( e.g. -1.763) and SE (e.g. 0.241). A quick calculation of the confidence interval would be \\(-1.763 \\pm 2 \\ \\times 0.241 = (-2.245, -1.281)\\). We interpret this as saying if we could collect 100 replicate data sets of the 16 annual surveys in the data set, and each time calculated a slope and an interval, 95% of those intervals would contain the true population trend (this is where the “frequentist” label in frequentist statistics comes from). We would be unable to make any probability statements about the trend itself; for example: it is incorrect to say the true trend has a 95% chance of being within our single interval. Our interval either contains the true value or it does not; we do not know for sure which.\nUnder the Bayesian paradigm, we can use the posterior distribution to make probability statements about the parameters. As an example, let’s look at the posterior distribution of the slope for our wallcreeper data.\nggplot() +\n  geom_histogram(aes(x = beta.samples)) +\n  geom_vline(xintercept = 0) +\n  xlab('Trend estimate')\nWe can see from the figure that none of the posterior distribution of beta falls to the right of zero. Thus we can say that the probability that the population constant or increasing is zero.",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#example",
    "href": "Lesson04_Regression.html#example",
    "title": "Lesson 4: regression",
    "section": "4.5 Example",
    "text": "4.5 Example",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#exercises",
    "href": "Lesson04_Regression.html#exercises",
    "title": "Lesson 4: regression",
    "section": "4.6 Exercises",
    "text": "4.6 Exercises",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson04_Regression.html#references",
    "href": "Lesson04_Regression.html#references",
    "title": "Lesson 4: regression",
    "section": "4.7 References",
    "text": "4.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 4: regression"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html",
    "href": "Lesson11_PoissonANCOVA.html",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 15",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#introduction",
    "href": "Lesson11_PoissonANCOVA.html#introduction",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.1 Introduction",
    "text": "11.1 Introduction\nAlthough the lesson and the chapter in Kéry (2010) reads “Poisson ANCOVA”, we can think of it at a Poisson regression with continuous and categorical explanatory variables. For most ecological applications, we are dealing with both types of variables. To emphasise the similarity to the general linear model, we will simulate a similar data set, this time with dragonflies, and we’ll look at variation in ectoparasite load (i.e. counts of mites per individual) among the three nature reserves Madikwe (Mad), Rietvlei (Rei) and Sabi Sands (Sab). Of particular interest in whether different reserves have different relationships between body size (i.e. wing length) and counts of mites. The model we will use is\nDistribution: \\(C_i \\sim {\\sf Poisson}(\\lambda_i)\\)\nLink function: log, \\(\\log(\\lambda_i) = \\log(E(C_i)) =\\) linear predictor\nLinear predictor: \\(\\log(\\lambda_i) = \\alpha_{Mad} + \\beta_1 \\times x_{Rei} + \\beta_2 \\times x_{Sab} + \\beta_3 \\times x_{wing} + \\beta_4 \\times x_{Rei} \\times x_{wing} + \\beta_5 \\times x_{Sab} \\times x_{wing}\\)\nThis model should look very similar to the one we fitted for puff adder lengths in lesson 7. To make it a GLM, we added a link function. The other difference is that there is no separate term for residual variation, because the Poisson distribution describes both the mean and the variability with the same term.",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#data-simulation",
    "href": "Lesson11_PoissonANCOVA.html#data-simulation",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.2 Data simulation",
    "text": "11.2 Data simulation\nHere is what our simulated data set will look like:\n# groups and sample sizes\nn.groups &lt;- 3\nn.sample &lt;- 100\nn &lt;- n.groups * n.sample\n\n# population indicator\nx &lt;- rep(1:n.groups, rep(n.sample, n.groups))\npop &lt;- factor(x, labels = c('Madikwe', 'Rietvlei', 'Sabi'))\n\n# wing length (cm); centre by subtracting the mean\nlength &lt;- runif(n, 4.5, 7.0)\nlength &lt;- length - mean(length)\n\n# design matrix\nXmat &lt;- model.matrix(~ pop*length)\n#print(Xmat, dig = 2) # have a look if you want\n\n# set the input parameters\nbeta.vec &lt;- c(-2, 1, 2, 5, -2, -7)\n\n# calculate linear predictor and Poisson means\nlin.pred &lt;- Xmat[,] %*% beta.vec\n\n# Up to here gives us expected mite count on a log scale\n\n# exponentiate to get actual count; add Poisson noise\nlambda &lt;- exp(lin.pred)\nC &lt;- rpois(n = n, lambda = lambda)\n\n# have a look\nggplot() +\n  geom_histogram(aes(x = C), bins = 30) +\n  xlab('Parasite load')\ndragonfl.df &lt;- data.frame(C, length, pop)\nggplot(data = dragonfl.df) +\n  geom_point(aes(x = length, y = C, colour = pop), size = 3) +\n  labs(x = 'Wing length', y = 'Parasite load')",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#classical-analysis-in-r",
    "href": "Lesson11_PoissonANCOVA.html#classical-analysis-in-r",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.3 Classical analysis in R",
    "text": "11.3 Classical analysis in R\nThe code for fitting a classical Poisson GLM in R is relatively straight-forward. We can fit the model and then compare to the input values in \\({\\tt beta.vec}\\).\nsummary(glm(C ~ pop * length, family = poisson))\nbeta.vec\nThe estimates and the input values are fairly close, but as you might expect there are some small differences. Remember that this is the consequence of sampling and estimation error. You could rerun the simulation and the analysis to get a sense of that variability between different data sets.",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#bayesian-analysis-with-bugs",
    "href": "Lesson11_PoissonANCOVA.html#bayesian-analysis-with-bugs",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.5 Bayesian analysis with BUGS",
    "text": "11.5 Bayesian analysis with BUGS\n\n11.4.1 Fitting the model\nWe’ll take the code from lesson 7, modify it for Poisson counts, and reparametrize for three separate log-linear regressions.\nmodel.PoisGLM &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:n.groups){\n    alpha[i] ~ dnorm(0, 0.01)       # intercepts\n    beta[i] ~ dnorm(0, 0.01)        # slopes\n  }\n  \n  # likelihood\n  for (i in 1:n){\n    C[i] ~ dpois(lambda[i])     # the random variable\n    lambda[i] &lt;- exp(alpha[pop[i]] + beta[pop[i]]* length[i])\n    # note double-indexing: alpha[pop[i]]\n  }\n  \n  # derived quantities\n  # recover effects relative to baseline level (no. 1)\n  a.effe2 &lt;- alpha[2] - alpha[1]        # intercept Rietvlei vs Madikwe\n  a.effe3 &lt;- alpha[3] - alpha[1]        # intercept Sabi vs Madikwe\n  b.effe2 &lt;- beta[2] - beta[1]      # slope Rietvlei vs Madikwe\n  b.effe3 &lt;- beta[3] - beta[1]      # slope Sabi vs Madikwe\n  \n  # custom test\n  test1 &lt;- beta[3] - beta[2]        # slope Sabi vs Rietvlei\n})\n\n# data and constants\nmy.data &lt;- list(C = C, pop = as.numeric(pop), length = length)\nmy.consts &lt;- list(n.groups = n.groups, n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rlnorm(n.groups, 3, 1),\n                            beta = rlnorm(n.groups, 2, 1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'a.effe2', 'a.effe3',\n               'b.effe2', 'b.effe3', 'test1')\n\n# MCMC settings\nni &lt;- 4500\nnb &lt;- 1500\nnt &lt;- 5\nnc &lt;- 3\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.PoisGLM,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1 &lt;- MCMCsummary(out1, round = 2)) # look at output\n# we're interested in alpha[1], beta[1], a.effe2, a.effe3, b.effe2, b.effe3\nbeta.vec # compare to input values\nprint(glm(C ~ pop * length, family = poisson)$coef, dig = 4) # classical solution\n \n\n\n11.4.2 Calculating predictions\nWe can summarise the main findings from the Bayesian analysis in the form of a graph, which will include the posterior distribution of the relationships between mite load and wing length for each nature reserve (both the expected counts and the 95% credible intervals). I will leave this for you as a practice exercise. There is code in Kéry (2010), but this is for WinBUGS and it won’t quite work with NIMBLE output. You can try two approaches: (1) use the existing output to calculate predictions in R; (2) modify the BUGS code to calculate the predictions for you there.\n# extract parameter estimates from MCs\nalpha1.sample &lt;- c(out1$chain1[,'alpha[1]'],\n                   out1$chain2[,'alpha[1]'],\n                   out1$chain3[,'alpha[1]'])\n\nbeta1.sample &lt;- c(out1$chain1[,'beta[1]'],\n                  out1$chain2[,'beta[1]'],\n                  out1$chain3[,'beta[1]'])\n\nalpha2.sample &lt;- c(out1$chain1[,'alpha[2]'],\n                   out1$chain2[,'alpha[2]'],\n                   out1$chain3[,'alpha[2]'])\n\nbeta2.sample &lt;- c(out1$chain1[,'beta[2]'],\n                  out1$chain2[,'beta[2]'],\n                  out1$chain3[,'beta[2]'])\n\nalpha3.sample &lt;- c(out1$chain1[,'alpha[3]'],\n                   out1$chain2[,'alpha[3]'],\n                   out1$chain3[,'alpha[3]'])\n\nbeta3.sample &lt;- c(out1$chain1[,'beta[3]'],\n                  out1$chain2[,'beta[3]'],\n                  out1$chain3[,'beta[3]'])\n\n# create a vector with 100 wing lengths\nn.samps &lt;- length(alpha1.sample)\noriginal.wlength &lt;- sort(runif(n.samps, 4.5, 7.0))\nwlength &lt;- original.wlength - mean(original.wlength)    # to centre\n\nmite.load.mad &lt;- exp(alpha1.sample + beta1.sample * wlength)\nmite.load.rie &lt;- exp(alpha2.sample + beta2.sample * wlength)\nmite.load.sab &lt;- exp(alpha3.sample + beta3.sample * wlength)\n\npred.df &lt;- data.frame(wlength, mite.load.mad, mite.load.rie, mite.load.sab)\nggplot(data = pred.df) +\n  geom_smooth(aes(x = wlength, y = mite.load.mad), colour = 'blue') +\n  geom_ribbon(aes(x = wlength, ymin = quantile(mite.load.mad, 0.025),\n                  ymax = quantile(mite.load.mad, 0.975)))",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#example",
    "href": "Lesson11_PoissonANCOVA.html#example",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.5 Example",
    "text": "11.5 Example",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#exercises",
    "href": "Lesson11_PoissonANCOVA.html#exercises",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.6 Exercises",
    "text": "11.6 Exercises",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson11_PoissonANCOVA.html#references",
    "href": "Lesson11_PoissonANCOVA.html#references",
    "title": "Lesson 11: Poisson ANCOVA",
    "section": "11.7 References",
    "text": "11.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 11: Poisson ANCOVA"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html",
    "href": "Lesson08_LinearMixed.html",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 12",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#introduction",
    "href": "Lesson08_LinearMixed.html#introduction",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nThis is going to be a foundational lesson for the rest of the course. Much of what we will do in the remaining lessons will require understanding and being able to code models that contain both fixed and random effects. Mixed-effects models are probably the single most important statistical tool in an ecologists toolbox because they are useful for many of the types of data that are collected in the environmental sciences.\nThere are at least three benefits to assuming a set of parameters are a random sample coming from a statistical distribution with its own (hyper)parameters to be estimated: (1) increased scope of inference, (2) more honest accounting for system uncertainty, and (3) efficiency of estimation. In this lesson we consider a standard mixed-effects linear model that arises as a direct generalisation of the ANCOVA model we have seen previously. We will return to our simulated snake study (Snakes? Did you say snakes?), but now we will use a larger number of populations (the textbook uses 56). Generally we wouldn’t need so many levels in our random effect to fit a mixed-effects model; 5–10 is usually sufficient if our goal is to get an accurate estimate of the variance they explain.\nWe will generate a new simulated data set, but constrain the values for at least one set of effects (intercepts or slopes) to come from a normal distribution. We will cover three possibilities when doing this:\n\nIntercepts are random, and the slope is identical for all groups (i.e. a random-intercept model).\nIntercepts and slopes are random, but they are independent (i.e. a random-coefficients model).\nIntercepts and slopes are random, and there is correlation between them (i.e. a random-coefficients model).\n\nHere is one way to write the random-coefficients model without correlation (model 2):\n\\[y_i = \\alpha_{j(i)} + \\beta_{j(i)} \\times x_i + \\epsilon_i\\]\n\\[\\alpha_j \\sim {\\sf Normal}(\\mu_{\\alpha}, \\sigma^2_{\\alpha})\\]\n\\[\\beta_j \\sim {\\sf Normal}(\\mu_{\\beta}, \\sigma^2_{\\beta})\\]\n\\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation:\n\\(y_i\\): mass of snake \\(i\\)\n\\(x_i\\): length of snake \\(i\\)\n\\(\\alpha_j\\): population-specific intercept\n\\(\\beta_j\\): population-specific slope\n\\(\\mu_{\\alpha}, \\mu_{\\beta}\\): means for independent normal distributions for \\(\\alpha\\) and \\(\\beta\\), respectively\n\\(\\sigma^2_{\\alpha}, \\sigma^2_{\\beta}\\): variances for independent normal distributions for \\(\\alpha\\) and \\(\\beta\\), respectively\n\\(\\epsilon_i\\): residuals for each snake \\(i\\) distributed as normal with variance \\(\\sigma^2\\)",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#data-simulation",
    "href": "Lesson08_LinearMixed.html#data-simulation",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.2 Data simulation",
    "text": "8.2 Data simulation\n# set up sample sizes and population indicator\nn.groups &lt;- 56              # no. populations\nn.sample &lt;- 10              # no. snakes in each pop\nn &lt;- n.groups * n.sample        # total no. data points\npop &lt;- gl(n = n.groups, k = n.sample)   # indicator for population\n\n# body length (cm)\noriginal.length &lt;- runif(n, 45, 70) \nmn &lt;- mean(original.length)\nsd &lt;- sd(original.length)\ncat(\"Mean and sd used to normalise.original length:\", mn, sd, \"\\n\\n\")\nlength &lt;- (original.length - mn) / sd\nhist(length, col = \"grey\")\n# design matrix\nXmat &lt;- model.matrix(~pop*length-1-length)\n#print(Xmat, dig = 2)       # if you want to see it\n\n# set values for parameters and effects\nintercept.mean &lt;- 230           # mu_alpha\nintercept.sd &lt;- 20          # sigma_alpha\nslope.mean &lt;- 60            # mu_beta\nslope.sd &lt;- 30              # sigma_beta\n\nintercept.effects &lt;- rnorm(n = n.groups, mean = intercept.mean,\n                           sd = intercept.sd)\nslope.effects &lt;- rnorm(n = n.groups, mean = slope.mean, sd = slope.sd)\nall.effects &lt;- c(intercept.effects, slope.effects) # put them all together\n\n# calculate values for response variable\nlin.pred &lt;- Xmat[,] %*% all.effects # value of lin.predictor\neps &lt;- rnorm(n = n, mean = 0, sd = 30)  # residuals \nmass &lt;- lin.pred + eps          # response = lin.pred + residual\n\n# have a look\nhist(mass, col = \"grey\")\nsnake.df &lt;- data.frame(mass, length, pop)\nggplot(data = snake.df) +\n  geom_point(aes(x = length, y = mass)) +\n  facet_wrap(~ pop, ncol = 8)",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#random-intercepts-model",
    "href": "Lesson08_LinearMixed.html#random-intercepts-model",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.3 Random-intercepts model",
    "text": "8.3 Random-intercepts model\n\n8.3.1 Classical analysis in R\nWe will be using function \\({\\tt lmer()}\\) to fit linear mixed-effects models. Classical analysis of such models occurs under restricted maximum likelihood (REML), which is useful for when working with unbalanced data. Our simulated data are balanced, but real data rarely are. To begin, we will assume that the mass–length relationship is the same across populations, and only the intercepts differ randomly among populations.\nlibrary('lme4')\nlme.fit1 &lt;- lmer(mass ~ length + (1 | pop), REML = TRUE)\nlme.fit1\n \n\n\n8.3.2 Bayesian analysis with BUGS\nWhen setting up the model in NIMBLE, we’ll need to use a wide uniform distribution for the standard deviation of the random-effects distribution.\n# specify the model\nmodel.lme1 &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:ngroups){\n    alpha[i] ~ dnorm(mu.int, sd = sigma.int)    # random intercepts\n  }\n  mu.int ~ dnorm(0, sd = 30)        # mean hyperparameter for random intercepts\n  sigma.int ~ dunif(0, 100)     # SD hyperparameter for random intercepts\n  \n  beta ~ dnorm(0, sd = 30)          # common slope\n  sigma ~ dunif(0, 100)         # residual standard deviation\n  \n  # Likelihood\n  for (i in 1:n){\n    mass[i] ~ dnorm(mu[i], sd = sigma)      # the random variable\n    mu[i] &lt;- alpha[pop[i]] + beta*length[i] # expectation\n  }\n})\n\n# data and constants\nmy.data &lt;- list(mass = as.numeric(mass), pop = as.numeric(pop), length = length)\nmy.consts &lt;- list(ngroups = max(as.numeric(pop)), n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(n.groups, 0, 2), beta = rnorm(1, 1, 1), mu.int = rnorm(1, 0, 1), sigma.int = rlnorm(1), sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'mu.int', 'sigma.int', 'sigma')\n\n# MCMC settings\nni &lt;- 2000\nnb &lt;- 500\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.lme1,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# look at output\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\n\n# compare with input values\nintercept.mean  ;  slope.mean  ;  intercept.sd  ;  slope.sd  ;  sd(eps)\nThe first thing you likely noticed is that it takes a while longer to run the chains. This will be the case with more complex models like those that will make up the rest of the course. Second is that the variance estimates don’t quite match. For example our simulated value for \\(sigma\\) is 30, but we estimated it to be &gt;40. This is because we simulated the data to have random variation among slopes. Because we did not fit that model here, that unaccounted for variation get absorbed in the residual standard deviation.",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#random-coefficients-model-no-correlation",
    "href": "Lesson08_LinearMixed.html#random-coefficients-model-no-correlation",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.4 Random-coefficients model (no correlation)",
    "text": "8.4 Random-coefficients model (no correlation)\n\n8.4.1 Classical analysis in R\nNext we will fit a model assuming there is variation in both intercepts and slopes among populations, but that there is no correlation between intercepts and slopes.\nlibrary('lme4')\nlme.fit2 &lt;- lmer(mass ~ length + (1|pop) + (0 + length|pop))\nlme.fit2\n \n\n\n8.4.2 Bayesian analysis with BUGS\nHere is the Bayesian analysis of the same data set, fitting the same random-coefficients model.\n# specify the model\nmodel.lme2 &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:ngroups){\n    alpha[i] ~ dnorm(mu.int, sd = sigma.int)    # random intercepts\n    beta[i] ~ dnorm(mu.slope, sd = sigma.slope)   # random slopes\n  }\n  \n  mu.int ~ dnorm(0, sd = 30)        # mean hyperparameter for random intercepts\n  sigma.int ~ dunif(0, 100)     # SD hyperparameter for random intercepts\n  \n  mu.slope ~ dnorm(0, sd = 30)      # mean hyperparameter for random slopes\n  sigma.slope ~ dunif(0, 100)       # SD hyperparameter for slopes\n  \n  sigma ~ dunif(0, 100)         # residual standard deviation\n  \n  # likelihood\n  for (i in 1:n){\n    mass[i] ~ dnorm(mu[i], sd = sigma)\n    mu[i] &lt;- alpha[pop[i]] + beta[pop[i]]*length[i]\n  }\n})\n\n# data and constants\nmy.data &lt;- list(mass = as.numeric(mass), pop = as.numeric(pop), length = length)\nmy.consts &lt;- list(ngroups = max(as.numeric(pop)), n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(n.groups, 0, 2),\n                            beta = rnorm(n.groups, 10, 2),\n                            mu.int = rnorm(1, 0, 1), sigma.int = rlnorm(1),\n                            mu.slope = rnorm(1, 0, 1), sigma.slope = rlnorm(1),\n                            sigma = rlnorm(1))\n\n# Parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'mu.int', 'sigma.int', 'mu.slope',\n               'sigma.slope', 'sigma')\n\n# MCMC settings\nni &lt;- 2000\nnb &lt;- 500\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout2 &lt;- nimbleMCMC(code = model.lme2,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# look at output\n(outSum2 &lt;- MCMCsummary(out2, round = 2))\n\n# compare with input values\nintercept.mean  ;  slope.mean  ;  intercept.sd  ;  slope.sd  ;  sd(eps)\nThis time we get fairly close agreement between simulated and estimated values, and this emphasises again the usefulness of using simulation to assess our models. If we recover estimates that match the input values, that gives us confidence that we’ve specified our model correctly.\nAlso important, is that we can get the estimated random effects from the model output. For the NIMBLE output, they are the values associated with the alpha[]’s and beta[]’s in the MCMC summary. For the classical analysis in R, we use the statement \\({\\tt ranef(lme.fit2)}\\).",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#random-coefficients-model-with-correlation",
    "href": "Lesson08_LinearMixed.html#random-coefficients-model-with-correlation",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.5 Random-coefficients model (with correlation)",
    "text": "8.5 Random-coefficients model (with correlation)\n\n8.5.1 Introduction\nNow we’ll have a look at the random-coefficients model with correlation between intercepts and slopes. It’s a relatively straight-forward extension of the previous model:\n\\[y_i = \\alpha_{j(i)} + \\beta_{j(i)} \\times x_i + \\epsilon_i\\] \\[(\\alpha_j,\\beta_j) \\sim MVN(\\mu, {\\bf \\Sigma})\\] \\[\\mu = (\\mu_{\\alpha}, \\mu_{\\beta})\\] \\[\n{\\bf \\Sigma} =\n\\left(\\begin{array}{cc}\n\\sigma^2_{\\alpha} & \\sigma_{\\alpha \\beta}\\\\\n\\sigma_{\\alpha \\beta} & \\sigma^2_{\\beta}\n\\end{array}\\right)\n\\]\n\\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation: the same as before, but now pairs of \\(\\alpha_j\\) and \\(\\beta_j\\) from each population \\(j\\) are assumed to come from a bivariate or multivariate normal distribution with mean vector \\(\\mu\\) and variance-covariance matrix \\({\\bf \\Sigma}\\). The matrix contains variances for the intercept (\\(\\sigma^2_{\\alpha}\\)) and slope (\\(\\sigma^2_{\\beta}\\)) in the diagonal, and covariances between \\(\\alpha_j\\) and \\(\\beta_j\\) (\\(\\sigma_{\\alpha \\beta}\\)) in the off-diagonals. If we have positive values for the covariance, that indicates steeper mass–length relationship for snakes with a greater mass.\n \n\n\n8.5.2 Data simulation\nHere we simulate data under the random-coefficients model with correlation. We will choose population-specific slopes and intercepts from a bivariate normal distribution having hyperparameters that we will need to set. The distribution of the residuals will once again be a normal distribution with mean zero and standard deviation of 30.\n# set up sample sizes and population indicator\nn.groups &lt;- 56\nn.sample &lt;- 10\nn &lt;- n.groups * n.sample \npop &lt;- gl(n = n.groups, k = n.sample)\n\n# body length (cm)\noriginal.length &lt;- runif(n, 45, 70)\nmn &lt;- mean(original.length)\nsd &lt;- sd(original.length)\ncat(\"Mean and sd used to normalise.original length:\", mn, sd, \"\\n\\n\")\nlength &lt;- (original.length - mn) / sd\nhist(length, col = \"grey\")\n# design matrix\nXmat &lt;- model.matrix(~pop*length-1-length)\n#print(Xmat[1:21,], dig = 2)        # have a look if you want\n\nlibrary(MASS)               # load MASS\n?mvrnorm                # check syntax\n\n# values for five hyperparameters\nintercept.mean &lt;- 230\nintercept.sd &lt;- 20\nslope.mean &lt;- 60\nslope.sd &lt;- 30\nintercept.slope.covariance &lt;- 10\n\n# set up mu vector and var-covar matrix\nmu.vector &lt;- c(intercept.mean, slope.mean)\nvar.cova.matrix &lt;- matrix(c(intercept.sd^2,intercept.slope.covariance,\n                            intercept.slope.covariance, slope.sd^2),2,2)\n\n# calculate and assemble effects\neffects &lt;- mvrnorm(n = n.groups, mu = mu.vector, Sigma = var.cova.matrix)\neffects                 # the intercepts and slopes for each population\napply(effects, 2, mean) # average intercept and slope among populations\nvar(effects) # var-covar matrix for our simulated data\n\nintercept.effects &lt;- effects[,1]\nslope.effects &lt;- effects[,2]\nall.effects &lt;- c(intercept.effects, slope.effects)\n\n# calculate values for response variable\nlin.pred &lt;- Xmat[,] %*% all.effects # value of lin.predictor\neps &lt;- rnorm(n = n, mean = 0, sd = 30)  # residuals \nmass &lt;- lin.pred + eps          # response = lin.pred + residual\n\n# have a look at the simulated data\nhist(mass, col = \"grey\")\nsnake.df &lt;- data.frame(mass, length, pop)\nggplot(data = snake.df) +\n  geom_point(aes(x = length, y = mass)) +\n  facet_wrap(~ pop, ncol = 8)\n\n\n8.5.3 Classical analysis in R\nBy default, the model we fit in R using the function \\({\\tt lmer()}\\) specifies correlation between slopes and intercepts.\nlibrary('lme4')\nlme.fit3 &lt;- lmer(mass ~ length + (length | pop))\nlme.fit3\n\n\n8.5.4 Bayesian analysis with BUGS\nWe will conduct the analysis in NIMBLE using one approach to specifying a random-coefficients model with correlation. This approach is useful for one random-effects variable.\n# Define model\n# specify the model\nmodel.lme3 &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:ngroups){\n    alpha[i] &lt;- B[i,1]\n    beta[i] &lt;- B[i,2]\n    B[i,1:2] ~ dmnorm(B.hat[i,], cov = Sigma.B[,])\n    B.hat[i,1] &lt;- mu.int\n    B.hat[i,2] &lt;- mu.slope\n  }\n  \n  mu.int ~ dnorm(0, sd = 30)        # hyperpriors for random intercepts\n  mu.slope ~ dnorm(0, sd = 30)      # hyperpriors for random slopes\n  \n  Sigma.B[1,1] &lt;- pow(sigma.int,2)\n  sigma.int ~ dunif(0, 100)     # SD of intercepts\n  Sigma.B[2,2] &lt;- pow(sigma.slope,2)\n  sigma.slope ~ dunif(0, 100)       # SD of slopes\n  Sigma.B[1,2] &lt;- rho*sigma.int*sigma.slope\n  Sigma.B[2,1] &lt;- Sigma.B[1,2]\n  rho ~ dunif(-1,1)\n  covariance &lt;- Sigma.B[1,2]\n  \n  sigma ~ dunif(0, 100)         # residual standard deviation\n  \n  # likelihood\n  for (i in 1:n){\n    mass[i] ~ dnorm(mu[i], sd = sigma)      # the 'residual' random variable\n    mu[i] &lt;- alpha[pop[i]] + beta[pop[i]]* length[i]  # expectation\n  }\n})\n\n# data and constants\nmy.data &lt;- list(mass = as.numeric(mass), pop = as.numeric(pop), length = length)\nmy.consts &lt;- list(ngroups = max(as.numeric(pop)), n = n)\n\n# initial values\nmy.inits &lt;- function() list(mu.int = rnorm(1, 0, 1), sigma.int = rlnorm(1),\n                            mu.slope = rnorm(1, 0, 1), sigma.slope = rlnorm(1),\n                            rho = runif(1, -1, 1), sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'mu.int', 'sigma.int', 'mu.slope',\n               'sigma.slope', 'rho', 'covariance', 'sigma')\n\n# MCMC settings\nni &lt;- 2000\nnb &lt;- 500\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampler\nout3 &lt;- nimbleMCMC(code = model.lme3,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc,\n                   dimensions = list(B.hat = c(n.groups, 2), Sigma.B = c(2, 2)))\n\n(outSum3 &lt;- MCMCsummary(out3, round = 2)) # Bayesian output\nlme.fit3                                          # classical output\nWe see that the estimates from the two methods are fairly close to each other, and to the input values set in the data simulation. The benefit we get by using NIMBLE over R is that we get an exact result rather than an asymptotic approximation. The trade-off is that it takes longer to reach convergence. As we move to more complex models, that time will increase further.\nFor some simulated data sets, the estimate of the correlation might be negative, even though we designed our data simulation to have a positive correlation. This happens as a consequence of sampling variation and estimation error. We get a sense of this when looking at the poor precision in the estimate of covariance, which is more difficult to estimate than a variance. We don’t get a standard error at all in R.",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#example",
    "href": "Lesson08_LinearMixed.html#example",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.6 Example",
    "text": "8.6 Example",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#exercises",
    "href": "Lesson08_LinearMixed.html#exercises",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.7 Exercises",
    "text": "8.7 Exercises",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson08_LinearMixed.html#references",
    "href": "Lesson08_LinearMixed.html#references",
    "title": "Lesson 8: linear mixed-effects models",
    "section": "8.8 References",
    "text": "8.8 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 8: linear mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html",
    "href": "Lesson09_GLM1.html",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 13",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#introduction",
    "href": "Lesson09_GLM1.html#introduction",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\nTwo unifications of separate methods have happened within applied statistics in recent decades. This first was recognising that t-tests, regression, ANOVA and ANCOVA were special cases of general linear models. The second combined these general linear models along with methods like logistic regression, multinomial regression, Chi-square tests and log-linear models into a broad category of methods called generalised linear models (GLMs). As such, the principles underlying any one type of linear model could be applied to a much broader class of models.\nThere are two advancements that make GLMs very useful tools in analysis of ecological data: (1) the expectation of the response \\(E(y)\\) can be transformed rather than using the expected or mean response itself, and (2) for the stochastic part of the model, we can use distributions other than normal (e.g. Poisson, binomial).\nA GLM contains three components:\n\na statistical distribution that describes the random variation in the response variable (referred to previously as “the stochastic bit”),\na link function g, which essentially transforms the response according to the way the response was measured, and\na linear predictor, or the covariate effects that are combined to explain variation in \\(g(E(y))\\) (referred to previously as “the deterministic bit”).\n\nThe most commonly used statistical distributions in GLM are binomial, Poisson and normal. The first two are suitable for counts because they describe discrete, non-negative integers. The third is useful for measurements (e.g. mass or length).\nThe most widely used link functions include the identity, logit (= log-odds = log(y/(1 - y))), and log. Typically we use a particular link function with a particular statistical distribution, but not necessarily always. For example, we can combine an identity link and a normal distribution to get a general linear model, a log link and the Poisson to get a log-linear model, and a logit link and the binomial to get a logistic regression. Thus the models from lessons 1–7 are all general linear models.\nFor the rest of the course, we will work from simple to more complex GLMs, beginning with a comparison between two groups in what Kéry (2010) calls a Poisson t-test, but we’ll begin with a standard (i.e normal) t-test that we started the course with, presented in GLM format:\n\nDistribution: \\(y_i \\sim {\\sf Normal}(\\mu_i, \\sigma^2)\\)\nLink function: identity, $_i = E(y_i) = $ linear predictor\nLinear predictor: \\(\\alpha + \\beta \\times x_i\\)\n\nNext, we’ll generalise this model to work with counts. The situation we’ll simulate will be counts of spring hares in 10 survey areas or plots each coming from modified agricultural land and natural bushveld. The question we’re asking is whether land use affects hare density.\nThe Poisson distribution is commonly used for this sort of count data, and the assumptions are that the hares are distributed randomly, independent, and we take random samples of equal size. This should give us hares counted per survey area (C) that are appropriate for a Poisson distribution. The distribution has a single parameter, \\(\\lambda\\), which is the expected count or intensity, but it also describes the variance (no separate variance parameter). In our case we can use it to describe hare density, and to test whether density differs between the two land uses. The model for hare count \\(C_i\\) in area \\(i\\):\n\nDistribution: \\(C_i \\sim {\\sf Poisson}(\\lambda_i)\\)\nLink function: log, $(_i) = (E(C_i)) = $ linear predictor\nLinear predictor: \\(\\alpha + \\beta \\times x_i\\)\n\nInterpretation:\n\\(C_i\\): hare count in area \\(i\\), distributed as a Poisson random variable\n\\(E(C_i) = \\lambda_i\\): the mean of the distribution\n\\(\\lambda_i\\): a linear function of \\(\\alpha + \\beta \\times x_i\\) when log-transformed\n\\(x_i\\): an indicator variable for agricultural land use\n\\(\\alpha\\): mean density of hares in bushveld (log-scale)\n\\(\\beta\\): mean difference in density between land-use types (log-scale)",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#important-assumption-about-count-data",
    "href": "Lesson09_GLM1.html#important-assumption-about-count-data",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.2 IMPORTANT ASSUMPTION ABOUT COUNT DATA",
    "text": "9.2 IMPORTANT ASSUMPTION ABOUT COUNT DATA\nWhen we do surveys of animals in the wild, we almost never count every animal. Nearly always we have imperfect detection, such that the probability of detecting an animal during a survey (\\(p\\)) is less than 1. In this example, however, we are assuming that, when we interpret \\(\\lambda\\), we have counted every hare in a survey area. Alternatively, we might assume that there is no difference between land-use types in terms of the probability of detecting animals, such that even if we have missed a some animals (giving us a relative density), the missed proportion is the same, and thus the counts or estimated densities are comparable. However, we need to be aware that detection probability too can differ between land-use types, and if we conclude a difference in \\(\\lambda_i\\) from survey counts, it might actually be a difference in detection. The only solution is to use a method of analysis that explicitly incorporates estimation of the detection probability–but we will not address that here.",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#data-simulation",
    "href": "Lesson09_GLM1.html#data-simulation",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.3 Data simulation",
    "text": "9.3 Data simulation\nWe will simulate and analyse count data assuming imperfect detection is not a problem.\n# indicator variable for land use\nn.sites &lt;- 10\nx &lt;- gl(n = 2, k = n.sites, labels = c('bushveld', 'agriculture'))\nn &lt;- 2*n.sites\n\n# set bushveld density to 2\n# set agriculture density to 5\n# alpha = log(2) = 0.69\n# log(5) = 0.69 + beta; beta = 0.92\nlambda &lt;- exp(0.69 + 0.92*(as.numeric(x)-1)) # x has levels 1 and 2, not 0 and 1\n\n# add Poisson variability, look at counts\nC &lt;- rpois(n = n, lambda = lambda)  # add Poisson noise\naggregate(C, by = list(x), FUN = mean)  # observed means\n\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = C)) +\n  xlab('Land-use') +\n  ylab('Hare count')",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#classical-analysis-in-r",
    "href": "Lesson09_GLM1.html#classical-analysis-in-r",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.4 Classical analysis in R",
    "text": "9.4 Classical analysis in R\nTo fit a “Poisson t-test” we will use the R function \\({\\tt glm(..., family = Poisson)}\\). To view the test itself we can use functions \\({\\tt summary()}\\) or \\({\\tt anova()}\\).\npoisson.t.test &lt;- glm(C ~ x, family = poisson) # fit the model\nsummary(poisson.t.test)         # t-test\nanova(poisson.t.test, test = \"Chisq\")   # likelihood ratio test (LRT)",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#bayesian-analysis-with-bugs",
    "href": "Lesson09_GLM1.html#bayesian-analysis-with-bugs",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.5 Bayesian analysis with BUGS",
    "text": "9.5 Bayesian analysis with BUGS\nNow we’ll fit the Poisson t-test model in NIMBLE. We can take the code for the normal t-test (lesson 3) and modify it for a Poisson GLM. Moreover, we will also\n\ncompute Pearson residuals to assess model fit;\nconduct a posterior predictive check, including calculating a Bayesian p-value like we did for linear regression.\n\n# specify the model\nmodel.poist &lt;- nimbleCode({\n  \n  # priors\n  alpha ~ dnorm(0, sd = 30)\n  beta ~ dnorm(0, sd = 30)\n  \n  # likelihood\n  for (i in 1:n){\n    C[i] ~ dpois(lambda[i])\n    log(lambda[i]) &lt;- alpha + beta *x[i]\n    \n    # fit assessments\n    Presi[i] &lt;- (C[i] - lambda[i]) / sqrt(lambda[i]) # Pearson resids\n    C.new[i] ~ dpois(lambda[i])     # replicate data set\n    Presi.new[i] &lt;- (C.new[i] - lambda[i]) / sqrt(lambda[i]) # Pearson resids\n    D[i] &lt;- pow(Presi[i], 2)\n    D.new[i] &lt;- pow(Presi.new[i], 2)\n  }\n  \n  # add up discrepancy measures\n  fit &lt;- sum(D[])\n  fit.new &lt;- sum(D.new[])\n})\n\n# data and constants\nmy.data &lt;- list(C = C, x = as.numeric(x)-1)\nmy.consts &lt;- list(n = length(x))\n\n# initial values\nmy.inits &lt;- function() list(alpha = rlnorm(1), beta = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('lambda', 'alpha', 'beta', 'Presi', 'fit', 'fit.new')\n\n# MCMC settings\nnc &lt;- 3\nni &lt;- 3000\nnb &lt;- 1000\nnt &lt;- 2\n\n# start Gibbs sampler\nout1 &lt;- nimbleMCMC(code = model.poist,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc,\n                   dimensions = list(D = c(n), D.new = c(n)))\n \n\n9.5.1 Check MCMC convergence and model adequacy\nFirst, we will look at the MCMCs to check (1) whether the chains have converged and that (2) the model is adequate for the data set. We assess convergence with graphical means or with numerical summaries (e.g. Brooks-Gelman-Rubin statistic or Rhat). We want Rhat to be close to 1 but take a value of 1.1 as an acceptable threshold for convergence. To see this:\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\nThe Rhat column in the output table suggests all parameters have reached convergence. We could also do more in-depth summaries for more complex models having many parameters. For example, which parameters have Rhat&gt;1.1, or we might assess Rhat values with a histogram.\n# Which value in the Rhat column is &gt; 1.1?\nwhich(outSum1[,'Rhat'] &gt; 1.1)\n\nggplot() +\n  geom_histogram(aes(x = outSum1[,'Rhat'])) +\n  labs(title = 'Rhat values')\nggplot() +\n  geom_point(aes(x = 1:20, y = outSum1$mean[1:20])) +\n  geom_hline(yintercept = 0)\nfit.samples &lt;- c(out1$chain1[,'fit'],\n                 out1$chain2[,'fit'],\n                 out1$chain3[,'fit'])\n\nfitnew.samples &lt;- c(out1$chain1[,'fit.new'],\n                    out1$chain2[,'fit.new'],\n                    out1$chain3[,'fit.new'])\n\nggplot() +\n  geom_point(aes(x = fit.samples, y = fitnew.samples)) +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab('Discrepancy measure for actual data set') +\n  ylab('Discrepancy measure for perfect data sets')\nOur graphical checks revealed no obvious problems. We can also calculate a Bayesian p-value from fit and fit.new values in the Markov chains.\nmean(fitnew.samples &gt; fit.samples)\n\n\n9.5.2 Inferences based on the model\nNow that we’re satisfied that the model is adequate for our data set, we can look at the estimates and compare them to the input values. Returning to the model output from earlier in the lesson, we see that the estimates for \\(\\alpha\\) and \\(\\beta\\) are pretty close to the values we used to generate the data set, for both the classical and the Bayesian analyses.\nGiven these estimates is there evidence of a difference in hare density between land use types? We can look at a histogram of the posterior distribution for the coefficient for land-use type.\nbeta.samples &lt;- c(out1$chain1[,'beta'],\n                  out1$chain2[,'beta'],\n                  out1$chain3[,'beta'])\n\nggplot() +\n  geom_histogram(aes(x = beta.samples), colour = 'black') +\n  labs(title = 'Coefficient for agriculture')\nBecause the posterior distribution does not overlap zero, we can conclude that there is strong evidence of a difference between land-use types. We can also make this conclusion from the output table: the 95% credible interval does not overlap with zero.\nFrom here, we can make predictions for presenting the results. These are the expected values of the response based on the values for our explanatory variables. We can do this using the posterior distributions from the Markov chains:\nalpha.samples &lt;- c(out1$chain1[,'alpha'],\n                   out1$chain2[,'alpha'],\n                   out1$chain3[,'alpha'])\n\nggplot() +\n  geom_histogram(aes(x = alpha.samples), colour = 'grey', fill = 'yellow') +\n  geom_histogram(aes(x = alpha.samples + beta.samples), colour = 'grey',\n                 fill = 'green') +\n  xlab('Expected hare count') +\n  annotate(geom = 'text', x = 0, y = 300, label = 'Bushveld') +\n  annotate(geom = 'text', x = 1.25, y = 600, label = 'Agricultre')",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#example",
    "href": "Lesson09_GLM1.html#example",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.6 Example",
    "text": "9.6 Example",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#exercises",
    "href": "Lesson09_GLM1.html#exercises",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.7 Exercises",
    "text": "9.7 Exercises",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson09_GLM1.html#references",
    "href": "Lesson09_GLM1.html#references",
    "title": "Lesson 9: introduction to generalised linear models",
    "section": "9.8 References",
    "text": "9.8 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 9: introduction to generalised linear models"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html",
    "href": "Lesson01_Introduction.html",
    "title": "Lesson 1: introduction",
    "section": "",
    "text": "Readings: Kéry (2010) chapters 1, 2, 5 (you might want to read chapters 3 and 4, but we won’t cover them directly)",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#some-introductory-theory",
    "href": "Lesson01_Introduction.html#some-introductory-theory",
    "title": "Lesson 1: introduction",
    "section": "1.1 Some introductory theory",
    "text": "1.1 Some introductory theory\nIt is not our goal to delve deeply into the theory of Bayesian statistics or statistical computation. If you are interested in that, have a look at Royle and Dorazio (2008), King et al. (2009) or Link and Barker (2010). However, it is still useful to have a sense of how the nuts and bolt work in a Bayesian analysis, so here we go.\n\nWe are interested in describing stochastic systems, that is, some degree of uncertainty about them.\nWe use a statistical model as the basis of that description; a model is an abstract description of how we believe our observations are the result of observable and unobservable quantities (i.e. parameters).\nOne of our goals is to use models containing parameters to obtain numerical estimates of those parameters.\nAnother goal is to search for useful models that can help us gain insight about systems that would otherwise be too complex to understand or predict.\nProbability and statistics are two avenues by which we learn about the characteristics of stochastic systems.\n\nWe use models and parameters to describe such systems and data to learn about their outcomes.\nProbability theory specifies parameters and a model, and examines a variable outcome (i.e. potential data).\nStatistics take data, assumes a model, and tries to infer system properties; i.e. making inferences via parameter estimates about a stochastic system by way of observed outcomes (i.e. collected data).",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#classical-versus-bayesian",
    "href": "Lesson01_Introduction.html#classical-versus-bayesian",
    "title": "Lesson 1: introduction",
    "section": "1.2 Classical versus Bayesian",
    "text": "1.2 Classical versus Bayesian\nClassical and Bayesian statistics are the two main views of how we should learn about parameter values in stochastic systems.\n\nBayesian statistics has been around for a very long time, since 1763 and Thomas Bayes.\nClassical (conventional, frequentist) statistics began only in the early 20th century.\n\nFor both paradigms: data are the observed realization of stochastic systems that contain at least one random process.\n\n\n\n\n\n\n\n\nParadigm\nParameters\nUncertainty\n\n\n\n\nClassical\nAssumed to be fixed, unknown constants\nDescribed in terms of hypothetical replicates\n\n\nBayesian\nTreated as realizations of random processes\nDescribed with a statistical distribution\n\n\n\nThe hypothetical replicates thus give the label “frequentist” to the classical approach. The statistical distribution in the Bayesian approach is called the “posterior distribution”, which is the conditional probability distribution of all unknown quantities (e.g. parameters), given the data, the model, and what we knew about the quantities before conducting the analysis (i.e. prior information).\nUnder Bayesian inference:\n\n\\(x\\) represents the observable quantities (data)\n\\(\\theta\\) represents unobservable or partially observable quantities; these could be statistical parameters, missing data or predicted values.\n\nAll are treated as random variables.\nThey can only be estimated probabilistically.\n\nWe can make probabilistic statements about them; for example, if our parameter of interest is population growth rate, and 24% of the posterior distribution is negative, we can say, “the probability that the population is decreasing is 24%.”\nBecause parameters are considered fixed in classical inference, such a statement makes no sense within that paradigm.\n\nFor both paradigms, we can talk about the sampling distribution \\(p(x|\\theta)\\) of data \\(x\\) as a function of a model with parameters \\(\\theta\\) (which can be a scalar or a vector).\n\nUnder classical\n\nThe likelihood function \\(p(x|\\theta)\\) or \\(L(x|\\theta)\\) is the basis for inference.\nWe use the function \\(L(x|\\theta)\\) to find the most likely value for \\(\\theta\\) based on the observed data.\nThe values of \\(\\theta\\) are called the maximum likelihood estimates.\n\nUnder Bayesian\n\nInference depends on Bayes Rule/Theorem, which is based on conditional probability.\nIt describes the relationship between two conditional probabilities, \\(p(A|B)\\) and \\(p(B|A)\\):\n\n\n\\[p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\\]\n\nWe can use this relationship to estimate the probability of parameters \\(\\theta\\) given data \\(x\\) (i.e. the posterior distribution \\(p(\\theta|x)\\)):\n\n\\[p(\\theta|x) = \\frac{p(x|\\theta)p(\\theta)}{p(x)}\\]\n\nThus, the posterior distribution \\(p(\\theta|x)\\) is proportional to \\(p(x|\\theta)\\) (the likelihood function) times the prior distribution of the parameters (\\(p(\\theta)\\)).\n\\(p(x)\\) is the normalizing constant, which makes \\(p(\\theta|x)\\) integrate to 1.\nHowever, because \\(p(x)\\) does not involve unknown \\(\\theta\\), we can treat it as a constant, and drop it from consideration. That leaves us with:\n\n\\[p(\\theta|x) \\propto p(x|\\theta)p(\\theta)\\]\nor, the posterior distribution in proportional to the likelihood times the prior distribution. This provides a rigorous mathematical statement about the probability parameter \\(\\theta\\), given the data, via the posterior distribution \\(p(\\theta|x)\\).\nClassical versus Bayesian:\n\nClassical methods estimate a single point for a parameter (the unknown constant).\nBayesian methods make inferences about an entire statistical distribution, by treating parameters as random variables described by a statistical distribution.\n\nCriticisms about “subjective priors”\n\nObjective science or statistics is an illusion anyway. We are always making decisions about what to study, what to measure and how to analyse.\nIt is possible to use uninformative priors; however, one needs to be sure they are uninformative on, for example, the log or logit scale as well as the linear scale.\nCould be an advantage rather than a disadvantage; we are required to be explicit about the assumptions we make, and to test or examine their influence on the analysis.",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#markov-chain-monte-carlo-mcmc-and-gibbs-sampling",
    "href": "Lesson01_Introduction.html#markov-chain-monte-carlo-mcmc-and-gibbs-sampling",
    "title": "Lesson 1: introduction",
    "section": "1.3 Markov chain Monte Carlo (MCMC) and Gibbs sampling",
    "text": "1.3 Markov chain Monte Carlo (MCMC) and Gibbs sampling\nMCMC is a set of tools to simulate draws from the posterior distribution \\(p(\\theta|x)\\) given a model, likelihood \\(p(x|\\theta)\\) and data. They use dependent sequences of random variables (i.e. samples from the posterior distribution of a parameter). Gibbs sampling is one such tool that is commonly used in Bayesian analysis.\nHow it works:\n\\(x\\) is data, \\(\\theta\\) a vector of unknowns (parameters) and we are estimating \\(k\\) of them;\n\nChoose starting values\n\n\\[\\theta_1^{(0)}, \\theta_2^{(0)}, ... \\theta_k^{(0)}\\]\n\n\nSample \\(\\theta_1^{(1)}\\) from\n\n\n\\[p(\\theta_1|\\theta_2^{(0)}, \\theta_3^{(0)}, ..., \\theta_k^{(0)}, x)\\]\n\n\nSample \\(\\theta_2^{(1)}\\) from\n\n\n\\[p(\\theta_2|\\theta_1^{(1)}, \\theta_3^{(0)}, ..., \\theta_k^{(0)}, x)\\] …\n\n\nSample \\(\\theta_k^{(1)}\\) from\n\n\n\\[p(\\theta_k|\\theta_1^{(1)}, \\theta_2^{(1)}, ..., \\theta_{k-1}^{(1)}, x)\\]\n\nRepeat all of step 2 (these are “updates” or “iterations”) many, many times; this gives us a sample from \\(p(\\theta|x)\\).\n\n\nAfter convergence, one draw (= sample) consists of \\(k\\) values from the joint probability distribution of \\(p(\\theta|x)\\).\nConditional distributions in this step are called full conditionals (i.e. they condition on the other parameters).\nThe sequence of random draws for each of \\(k\\) parameters resulting from step 3 forms a Markov chain.\n\nTo summarize the basics of a Bayesian analysis:\n\nWe use a degree-of-belief definition of probability rather than that based on frequency of hypothetical replicates.\nWe use probability distributions to summarize our belief or knowledge about each model parameter and apply Bayes rule to update knowledge with observed data to get posterior distributions for every unknown in the model.\n\n\nPosterior distribution: quantifies all our knowledge about these unknowns given data, model and prior assumptions.\nStatistical inference is based on posterior distributions.\n\n\nWe use simulations (MCMC) to draw a series of dependent samples from from the posterior distribution, and base inference on that sample.\n\nExample This code uses MCMC to estimate a standard normal distribution (from Link and Barker 2010)\nnsamp &lt;- 100000 # number of iterations\nA &lt;- 3.7 # tuning parameter\nX &lt;- rep(NA, nsamp) # empty vector to hold MCMC values\nX[1] &lt;- 0 # initial value\nfor(i in 2:(nsamp+1)){\n  u1 &lt;- runif(1, 0, 1) # uniform random number\n  u2 &lt;- runif(1, 0, 1) # uniform random number\n  # new candidate X based on A, u1, current X\n  X.cand &lt;- X[i-1] + 2*A*(u1 - 1/2)\n  # success parameter\n  # ratio of SN density at X(cand) to SN density at X(t-1)\n  r &lt;- exp(-0.5*X.cand^2)/exp(-0.5*X[i-1]^2)\n  # if r is larger than u2 set X(t) = X(cand), otherwise X(t) = X(t-1)\n  ifelse(u2 &lt; r, X[i] &lt;- X.cand, X[i] &lt;- X[i-1])\n}\n\n# plot first 50 samples\nplot(X[1:50], type = 'l')\nhist(X)\nIn words, the algorithm generates a series of random values. This one uses uniform random number generators. Each candidate random number is evaluated for whether it is include in the sample, based on the ratio of the standard normal density at that value to the density at the previous value. The tuning parameter “A” affects how often a candidate value is accepted or rejected. The trick is to set A so that not too many candidates are accepted or rejected; that is, we want a a sampler that is efficient.\nWhen we run a model in NIMBLE the MCMC algorithm spends some time at first adjusting the tuning parameters before the chains run. This is called the adaptation phase. After this is burn-in, when the Markov chains are allowed to run from their initial values and converge on parameter estimates. After that, the iterations or draws used for inference are generated. Ideally we want to use more than 1 Markov chain, each starting from a different initial value. Three chains are common in Bayesian analysis.",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#once-we-have-the-markov-chains",
    "href": "Lesson01_Introduction.html#once-we-have-the-markov-chains",
    "title": "Lesson 1: introduction",
    "section": "1.4 Once we have the Markov chains…?",
    "text": "1.4 Once we have the Markov chains…?\nOnce the Markov chains stop running, we are left with a series of random numbers from the joint posterior distribution \\(p(\\theta|x)\\). From an example we’ll encounter later (a model of the mean), we could have values for the two parameters that look like this:\n\\[\\mu: 4.28, 6.09, 7.37, 6.10, 4.72, 6.67...\\] \\[\\sigma^2: 10.98, 11.23, 15.26, 9.17, 9.17, 14.82, 18.19...\\]\nNext steps:\n\nMake sure the MCMCs have converged on stable parameter estimates.\n\nThe chain values should not be influenced by the choice of starting values, so we allow some time for the effect to initial values to disappear. We do this by discarding the burn-in iterations once convergence in apparent.\nChecks of convergence\n\nPlot parameter MCMC values against iteration number (a “traceplot”). The Markov chains should jiggle around a lot (giving a “grassy” appearance to the graph) but have no trend.\nLook at the Brooks-Gelman-Rubin statistic. It should be calculated automatically if you ran your analysis with more than one chain. It compares between- and within-chain variation in a way similar to an ANOVA. Values near 1 (generally &lt;1.1) indicate convergence.\n\nIt is important to do both of these checks; one check alone is not enough to assure convergence.\n\nSummarize samples to estimate mean, mode, standard deviation, 95% CRIs. Because we are estimating a distribution rather than a single point, we need summaries of that distribution.\nCompute posterior distributions for derived variables. It’s easy to calculate any function of model parameters, along with exact standard errors, while fully accounting for all the uncertainty involved in computing the function, without the need for approximations like the delta method. For example, we might calculate a rate of population change from two consecutive estimates of abundance: \\(N_2 / N_1 = \\lambda\\). Uncertainty in the estimation of \\(\\lambda\\) is incorporated from the two estimates of \\(N\\).\nForm predictions from model output. We can calculate predicted values of response variables with uncertainty. Those predictions are functions of parameters and data; their posterior distributions can be used for inference. The mean and 95% CRIs can be used as the prediction value and 95% prediction interval.",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#some-comments-on-statistical-modelling-whether-bayesian-or-classical",
    "href": "Lesson01_Introduction.html#some-comments-on-statistical-modelling-whether-bayesian-or-classical",
    "title": "Lesson 1: introduction",
    "section": "1.5 Some comments on statistical modelling, whether Bayesian or classical",
    "text": "1.5 Some comments on statistical modelling, whether Bayesian or classical\nChecking model adequacy\n\nFor simple models (linear models or generalize linear models), the standard model diagnostics based on residuals (e.g. plots of residuals versus fitted values, histograms) are generally adequate.\nFor complex, hierarchical models, checking is not so simple. Some methods for checking:\n\ninternal cross-validation;\nvalidation against external data;\nposterior predictive checks (e.g. Bayesian \\(p\\)-values for measuring goodness-of-fit of models to data)\n\n\nHypothesis testing and model selection\n\nWe can test whether a parameter does not equal some hypothesized value (e.g. zero) by whether CRIs overlap that value, as with classical statistics.\nBut we can also make direct probability statements about the magnitude of a value.\nWe can use indicator variables (\\(w\\)) multiplied by a parameter to assess the probability that it belongs in a model.\n\nWe define a prior distribution: \\(w \\sim {\\sf Bernoulli}(p = 0.5)\\)\nThe posterior distribution for \\(w\\) gives the probability that the associated effect belongs in the model\nIt can also be used to calculate model-averaged estimates of parameters, but the MCMCs run very slowly.\n\nFor model selection in non-hierarchical models (e.g. linear and generalized liner), deviance information criterion (DIC) works exactly like Akaikes information criterion (AIC) in classical statistics.\n\nIt expresses a trade-off between model fit and model complexity.\nCalculated as deviance \\(+ 2 \\times\\) the effective number of parameters.\nFor hierarchical models, this method gets complicated and is not particularly reliable.\nReversible-jump MCMC is useful for figuring deciding how much complexity belongs in a model. More to come.\n\n\nIn the minds of ecologists, the model selection problem (based on classical statistics, AIC and its variants) seems to have been solved. Among statisticians, this is not generally considered true.\nParameter identifiability\n\nA parameter is identifiable if there is enough information in the data to estimate the parameter unambiguously.\nThis is generally not an issue in Bayesian analysis. At worst, the posterior distribution will be the same as the prior distribution; a useful test for identifiability is to compare prior and posterior distributions for a parameter.\nA lack of convergence could indicate lack of identifiability, but this could be caused by other problems, too.\nWe can use data simulation and an estimated model to see whether we can recover the original parameter values.",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#model-of-the-mean",
    "href": "Lesson01_Introduction.html#model-of-the-mean",
    "title": "Lesson 1: introduction",
    "section": "1.6 Model of the mean",
    "text": "1.6 Model of the mean\nSimulate two data sets of body masses, one for 10 birds and one for 1000:\nlibrary(tidyverse)\n\n### Simulate data sets\n# Generate two samples of body mass measurements of male peregrines\ny10 &lt;- rnorm(n = 10, mean = 600, sd = 30) # Sample of 10 birds\ny1000 &lt;- rnorm(n = 1000, mean = 600, sd = 30) # Sample of 1000 birds\n\n# Plot data\npar(mfrow = c(2,1))\nggplot() +\n  geom_histogram(mapping = aes(x = y10), binwidth = 20, colour = 'white') +\n  xlim(450, 750) +\n  labs(title = 'Body mass (g) of 10 male peregrines')\nggplot() +\n  geom_histogram(mapping = aes(x = y1000), binwidth = 20, colour = 'white') +\n  xlim(450, 750) +\n  labs(title = 'Body mass (g) of 1000 male peregrines')\nAnalysis using R\nsummary(lm(y1000) ~ 1)\nAnalysis using NIMBLE\nlibrary(nimble)\nlibrary(MCMCvis)\n\n# specify the model\nmodel.pere1 &lt;- nimbleCode({\n  \n  # Priors\n  population.mean ~ dunif(0, 5000)\n  population.variance &lt;- population.sd * population.sd\n  population.sd ~ dunif(0, 100)\n  \n  # Likelihood\n  for(i in 1:nobs){\n    mass[i] ~ dnorm(population.mean, sd = population.sd)\n    }\n})\nPackage all the information needed for NIMBLE to run the analysis (data and constants). Data are observations of variables that have some random element to them. Constants are fixed quantities that do not change (like the size of a sample once data collection is finished).\n# Bundle data to be passed to NIMBLE\n# Constants and data must be specified separately\nmy.constants &lt;- list(nobs = length(y1000))\nmy.data &lt;- list(mass = y1000)\nDefine a function that specifies random starting values for the Markov chains. Specify the parameters we want NIMBLE to keep track of (things we want estimates for). Settings for Markov chains: no. chains, no. draws from posterior for each chain, no. burn-in iterations that are discarded, and thinning rate.\nHow to choose iterations.\n# Function to generate starting values\nmy.inits &lt;- initial.values &lt;- function() list(population.mean = rnorm(1,600),\n                                              population.sd = runif(1, 1, 30))\n\n# Parameters to be monitored (= to estimate)\nmy.params &lt;- c('population.mean', 'population.sd', 'population.variance')\n\n# MCMC settings\nnc &lt;- 3                 # Number of chains\nni &lt;- 1000          # Number of draws from posterior (for each chain)\nnb &lt;- 1                 # Number of draws to discard as burn-in\nnt &lt;- 1                 # Thinning rate\nFinally, we use the function \\(\\tt{nimbleMCMC()}\\) to run the run the analysis and save results in the object \\(\\tt{out}\\)\n# Start Gibbs sampler: Run model in NIMBLE and save results in object called 'out'\nout &lt;- nimbleMCMC(code = model.pere1,\n                  data = my.data,\n                  constants = my.constants,\n                  inits = my.inits,\n                  monitors = my.params,\n                  thin = nt, niter = ni, nburnin = nb, nchains = nc)\nYou’ll see text showing NIMBLE setting up the analysis, then a pause… it might feel like a long pause, but don’t panic… then you can see the progress of chains running. When it is finished, the object \\({\\tt out}\\) appears in the workspace. Let’s have a look.\n# Information contained in the object 'out'\nnames(out)\nstr(out)\nThe object \\({\\tt out}\\) is a list containing the three Markov chains. We can look at the size of each chain:\ndim(out$chain1)\nThe dimensions reflect the number of iterations (i.e. niter – nburnin) and the number of parameters we are estimating. We can look at the first few values in one of the chains like this:\nhead(out$chain1)\nWe see a column of values for each parameter we were estimating. If we want to make inferences from these values, we need to compute posterior summaries:\n# the mean of each parameter for chain1\nmean(out$chain1[,'population.mean'])\nmean(out$chain1[,'population.sd'])\nmean(out$chain1[,'population.variance'])\n\n# the 95% credible interval for each parameter in chain1\nquantile(out$chain1[,'population.mean'], probs = c(0.025, 0.975))\nquantile(out$chain1[,'population.sd'], probs = c(0.025, 0.975))\nquantile(out$chain1[,'population.variance'], probs = c(0.025, 0.975))\n\n# histogram of posterior distribution of population.mean for chain1\nout %&gt;%\n  as_tibble() %&gt;%\n  ggplot() +\n  geom_histogram(aes(x = chain1[,'population.mean']), color = \"white\") + \n  xlab('Mean body mass (g)')\nA much easier way to summarize the Markov chain values is to use a summarizing function like MCMCsummary in library MCMCvis:\nlibrary(MCMCvis)\n\n# the combined summary of the values of all Markov chains\nMCMCsummary(out, round = 2)\n\n# to plot the estimates and 95% CRIs:\nMCMCplot(object = out)\n# trace plots and densities of the chains\nMCMCtrace(out, pdf = FALSE, ind = TRUE, Rhat = TRUE, n.eff = TRUE)\nWe’ll learn later about how to interpret the graphs.",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#exercises",
    "href": "Lesson01_Introduction.html#exercises",
    "title": "Lesson 1: introduction",
    "section": "1.7 Exercises",
    "text": "1.7 Exercises",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson01_Introduction.html#references",
    "href": "Lesson01_Introduction.html#references",
    "title": "Lesson 1: introduction",
    "section": "1.8 References",
    "text": "1.8 References\nIf you want to learn more about NIMBLE, I recommend these online resources:\nhttps://oliviergimenez.github.io/nimble-workshop/\nhttps://oliviergimenez.github.io/banana-book/intronimble.html\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.\nKing R, Morgan BJT, Gimenez O, Brooks SP (2009) Bayesian analysis for population ecology. CRC Press, Boca Raton, USA.\nLink WA, Barker, RJ (2010) Bayesian inference with ecological applications. Academic Press, London, UK.\nRoyle JA, Dorazio RM (2008) Hierarchical modelling and inference in ecology. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 1: introduction"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html",
    "href": "Lesson03_TTest.html",
    "title": "Lesson 3: t-test",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 7\nMost people wouldn’t think of the simple t-test as a linear model, but that is precisely what it is. In this lesson we will introduce ourselves to specifying linear models in BUGS using this starting point, and we will specify the “t-test model” for equal and unequal variances.",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html#t-test-with-equal-variances",
    "href": "Lesson03_TTest.html#t-test-with-equal-variances",
    "title": "Lesson 3: t-test",
    "section": "3.1 t-test with equal variances",
    "text": "3.1 t-test with equal variances\n\n3.1.1 Introduction\nThe model underlying the t-test with equal variances is:\n\\(y_i = \\alpha + \\beta \\times x_i + \\epsilon_i\\)\n\\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)\nInterpretation:\n\\(y_i\\): the response, a continuous variable measured for each unit \\(i\\) in the sample\n\\(x_i\\): is an indicator variable for group 2\n\\(\\alpha\\): the mean for group 1\n\\(\\beta\\): the difference between groups 1 and 2\n\\(\\epsilon_i\\): the residuals around the group means\n\\(\\sigma^2\\): the variance of the distribution of the residuals\n\n \n\n\n3.1.2 Data simulation\n\nWe will simulate data based on peregrine falcons that we encountered in an earlier lesson.\nWe’ll imagine that we have wingspan measurements for males and females, that they’re normally distributed, and we’ll assume that the mean and standard deviation are 77.5 and 2.5 cm for males and 105 and 3 cm for females.\n\nn1 &lt;- 60                    # Number of females\nn2 &lt;- 40                    # Number of males\nmu1 &lt;- 105                  # Population mean of females\nmu2 &lt;- 77.5                 # Population mean of males\nsigma &lt;- 2.75               # Average population SD of both\nn &lt;- n1 + n2                # Total sample size\ny1 &lt;- rnorm(n1, mu1, sigma) # Data for females\ny2 &lt;- rnorm(n2, mu2, sigma) # Date for males\ny &lt;- c(y1, y2)              # Aggregate both data sets\nx &lt;- rep(c(0,1), c(n1, n2)) # Indicator for male\n\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = y)) +\n  xlab('Male') +\n  ylab('Wingspan (cm)')\nThe method we used to generate these data correspond to a means parameterization. We could also generate a data set in a manner that demonstrates effects parameterization.\nn &lt;- n1 + n2                  # Total sample size\nalpha &lt;- mu1                  # Mean for females serves as the intercept\nbeta &lt;- mu2 - mu1             # Beta is the difference male-female\nE.y &lt;- alpha + beta*x         # Expectation\ny.obs &lt;- rnorm(n = n, mean = E.y, sd = sigma) # Add random variation\n\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = y.obs)) +\n  xlab('Male') +\n  ylab('Wingspan (cm)')\nRepeatedly executing this code chunk gives us a sense of the effect of chance (sampling variance or sampling error) on the resulting data, and the differences between repeated realizations of the same random process.\n \n\n\n3.1.3 Classical analysis in R\nTo analyse our simulated data with a linear model in R:\nfit1 &lt;- lm(y ~ x)     # Analysis of first data set\nfit2 &lt;- lm(y.obs ~ x) # Analysis of second data set\n\nsummary(fit1)\nsummary(fit2)\nThe differences between the two analyses are the consequence of sampling variation. To get an ANOVA table for the two models:\nanova(fit1)\nanova(fit2)\nWe can also look at the design matrices:\nmodel.matrix(fit1)\nmodel.matrix(fit2)\n \n\n\n3.1.4 Bayesian analysis with BUGS\nHere is an analysis of the first data set using the Bayesian approach and NIMBLE:\nlibrary(nimble)\n\n# specify the model\nmodel.ttest1 &lt;- nimbleCode({\n  \n  # Priors\n  mu1 ~ dnorm(0, sd = 30)\n  delta ~ dnorm(0, sd = 30)\n  sigma ~ dunif(0, 100)\n  \n  # Likelihood\n  for (i in 1:n) {\n    y[i] ~ dnorm(mu[i], sd = sigma)\n    mu[i] &lt;- mu1 + delta*x[i]\n    residual[i] &lt;- y[i] - mu[i] # define residuals\n  }\n  \n  # D4erived quantities: one of the greatest things about a Bayesian analysis\n  mu2 &lt;- mu1 + delta # Difference in wingspan\n})\nNext we must specify:\n\nthe data\nthe constants\ninitial values\nparameters we want NIMBLE to remember for us\nthe Markov chain Monte Carlo (MCMC) settings\n\nThen we send everything to NIMBLE.\n# data and constants\nmy.data &lt;- list(x = x, y = y)\nmy.consts &lt;- list(n = n)\n\n# initial values\nmy.inits &lt;- function() list(mu1 = rnorm(1), delta = rnorm(1),\n                            sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('mu1','mu2', 'delta', 'sigma', 'residual')\n\n# MCMC settings\nnc &lt;- 3     # no. chains\nni &lt;- 1000  # no. draws from posterior for each chain\nnb &lt;- 1     # no. draws to discard as burn in\nnt &lt;- 1     # thinning rate\n\n# start Gibbs sampler\nout1 &lt;- nimbleMCMC(code = model.ttest1,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# save the summary for graphing\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\nComparison of classical and Bayesian analyses:\n\nMean estimates are almost identical.\nThe residual standard deviation estimate (i.e. residual standard error in classical versus sigma in Bayesian) is slightly larger in the Bayesian analysis. This difference stems from the approximate asymptotic nature of frequentist inference compared to the exact inference under the Bayesian paradigm.\nVery nice feature in Bayesian: derived parameters (mu2) that are functions of underlying parameters plus there uncertainties (mu1 and delta) can be obtained easily using the MCMC posterior samples. Unlike in classical analysis where the delta method would be needed, error from estimation is automatically propagated into functions of parameters.\n\nFurther comments:\n\nThe effective number of parameters to be estimated is three: one variance (sigma) and two means (mu1, mu2).\nBefore we use this or any model for inference we should check that it is adequate. Because we simulated data, the model should be adequate, but with real data we would want to a further assessment with the residuals.\nFor practice, we’ll assess model adequacy with our residuals. One observation is that each residual has its own posterior distribution, which might seem odd. But in Bayesian analysis, each calculated or estimated value (i.e. an unknown) has some degree of uncertainty represented by its posterior distribution.\n\nWe’ll plot the residual against the order of the individual in our data set, then we’ll assess the spread of residuals with box-plots to judge whether the spread is similar:\nggplot() +\n  geom_point(aes(x = 1:100, y = outSum1$mean[4:103])) +\n  geom_hline(yintercept = 0) +\n  xlab('Individual') +\n  ylab('Wingspan residuals (cm)')\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = outSum1$mean[4:103])) +\n  geom_hline(yintercept = 0) +\n  xlab('Male') +\n  ylab('Wingspan residuals (cm)')\nNo pattern in the first graph, and the box-plots look similar. No evidence of violations.",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html#t-test-with-unequal-variances",
    "href": "Lesson03_TTest.html#t-test-with-unequal-variances",
    "title": "Lesson 3: t-test",
    "section": "3.2 t-test with unequal variances",
    "text": "3.2 t-test with unequal variances\n\n3.2.1 Introduction\nWe’re now moving to the situation where variances are unequal between groups, something that is common in real data sets. We can modify the model from the equal-variance situation to accommodate unequal variance as follows:\n\\(y_i = \\alpha + \\beta \\times x_i + \\epsilon_i\\)\n\\(\\epsilon \\sim {\\sf Normal}(0, \\sigma_1^2)\\) when \\(x_i = 0\\) (females)\n\\(\\epsilon \\sim {\\sf Normal}(0, \\sigma_2^2)\\) when \\(x_i = 1\\) (males)\n\n\n\n3.2.2 Data simulation\nHere is the code to simulate data under the heterogeneous group model:\nn1 &lt;- 60                # Number of females\nn2 &lt;- 40                # Number of males\nmu1 &lt;- 105              # Population mean for females\nmu2 &lt;- 77.5             # Population mean for males\nsigma1 &lt;- 3             # Population SD for females\nsigma2 &lt;- 2.5               # Population SD for males\n\nn &lt;- n1 + n2                # Total sample size\ny1 &lt;- rnorm(n1, mu1, sigma1)        # Data for females\ny2 &lt;- rnorm(n2, mu2, sigma2)        # Data for males\ny &lt;- c(y1, y2)              # Aggregate both data sets\nx &lt;- rep(c(0, 1), c(n1, n2))        # Indicator for male\n\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = y)) +\n  xlab('Male') +\n  ylab('Wingspan residuals (cm)')\n\n\n3.2.3 Classical analysis in R\nWe can analyse data with heterogeneous variances in the classical paradigm using Welch’s test. This is the default when using the function \\({\\tt t.test}\\):\nt.test(y ~ x)\n\n\n3.2.4 Bayesian analysis with BUGS\nHere we specify the model using BUGS code and NIMBLE.\n# specify the model\nmodel.ttest2 &lt;- nimbleCode({\n  \n  # Priors\n  mu1 ~ dnorm(0, sd = 30)\n  mu2 ~ dnorm(0, sd = 30)\n  sigma1 ~ dunif(0, 1000)\n  sigma2 ~ dunif(0, 1000)\n  \n  # Likelihood\n  for (i in 1:n1){\n    y1[i] ~ dnorm(mu1, sd = sigma1)\n  }\n  \n  for (i in 1:n2){\n    y2[i] ~ dnorm(mu2, sd = sigma2)\n  }\n  \n  # Derived quantities\n  delta &lt;- mu2 - mu1\n})\n\n# data and constants\nmy.data &lt;- list(y1 = y1, y2 = y2)\nmy.consts &lt;- list(n1 = n1, n2 = n2)\n\n# initial values\nmy.inits &lt;- function() list(mu1 = rnorm(1), mu2 = rnorm(1),\n                            sigma1 = rlnorm(1), sigma1 = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('mu1','mu2', 'delta', 'sigma1', 'sigma2')\n\n# MCMC settings\nnc &lt;- 3     # no. chains\nni &lt;- 2000  # no. draws from posterior for each chain\nnb &lt;- 500   # no. draws to discard as burn in\nnt &lt;- 1     # thinning rate\n\n# start Gibbs sampler\nout2 &lt;- nimbleMCMC(code = model.ttest2,\n                  data = my.data,\n                  constants = my.consts,\n                  inits = my.inits,\n                  monitors = my.params,\n                  thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# save the summary for graphing\n(outSum2 &lt;- MCMCsummary(out2, round = 2))\nHeterogeneous group variances are easy to deal with in a Bayesian framework.\n\nIf we wanted to formally test for a differences in variances, we could reparameterise to make one variance equal to the other variance plus a constant to be estimated.\nThis could be done within NIMBLE or in R with the saved Markov chain values for \\(sigma1\\) and \\(sigma2\\) (the latter is often easier).\nIf the posterior distribution covers zero, that could be taken as evidence for a lack of difference.",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html#summary",
    "href": "Lesson03_TTest.html#summary",
    "title": "Lesson 3: t-test",
    "section": "3.3 Summary",
    "text": "3.3 Summary\nAlthough easy to conduct a t-test using the canned R function, building our own in BUGS language has helped us to learn some necessary lessons:\n\nBayesian modelling has flexibility to allow us to accommodate peculiarities of a particular data set (like heterogeneous group variances).\nWe can model not just the mean, but whatever parameter we need to (like sigma) to address a question or objective. We could even use covariates.\nModelling variance is relatively easy in the Bayesian paradigm, whereas in the classical paradigm it can be difficult for anyone but a hard-core statistician.",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html#example",
    "href": "Lesson03_TTest.html#example",
    "title": "Lesson 3: t-test",
    "section": "3.4 Example",
    "text": "3.4 Example",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html#exercises",
    "href": "Lesson03_TTest.html#exercises",
    "title": "Lesson 3: t-test",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson03_TTest.html#references",
    "href": "Lesson03_TTest.html#references",
    "title": "Lesson 3: t-test",
    "section": "3.6 References",
    "text": "3.6 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 3: t-test"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html",
    "href": "Lesson10_GLM2.html",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 14\nOver-dispersion and offsets are two features that are specific to generalized linear models (GLMs) that involve counts. One common type of over-dispersion is one in which there are more zeros than expected; this is called zero-inflation. In this lesson we will address each in the context of the scrub hare example.",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html#overdispersion",
    "href": "Lesson10_GLM2.html#overdispersion",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "10.1 Overdispersion",
    "text": "10.1 Overdispersion\n\n10.1.1 Introduction\nFor both the Poisson and the binomial distributions, the variability in counts (i.e. the dispersion) is a function of the mean, rather than a separate parameter. For the Poisson, the mean and the variance are both \\(\\lambda\\), and for the binomial, the variance is \\(N \\times p \\times (1 - p)\\). As a consequence, for both these parameters, the variance is “built-in” and known if the mean is known. If we fit a GLM to count data, the measure of the variability (the deviance) should be approximately the same value as the residual degrees of freedom, so that their ratio (the mean deviance ratio) is approximately equal to 1.\nFor count data from the real world, however, it’s common to have counts that are more variable than expected under binomial or Poisson models. We call this over-dispersion, or extra-Poisson or extra-binomial variation, and the residuals are larger than they should be for these distributions. Over-dispersion is common when there are dependencies in our data, such as when animals in groups are treated as independent or important covariates have not been included in the model. The consequence is that confidence intervals will be too narrow and tests more likely to conclude a difference, although it generally won’t affect bias in the means.\nIn a classical analysis, we can address over-dispersion in the function \\({\\tt glm()}\\) by setting \\({\\tt family = quasipoisson}\\) or \\({\\tt quasibinomial}\\). In BUGS we can specify a distribution like the negative binomial. Also we could add a linear predictor for the Poisson intensity (a normally-distributed random effect). Such a model can be called a Poisson generalized linear mixed model (GLMM) or a Poisson-lognormal model.\n \n\n\n10.1.2 Data simulation\nWe repeat our scrub hare data set from lesson 9, but this time we add a normally-distributed site-specific effect in the linear predictor. We will compare to a similar data set without this effect, so you can see what the difference is.\nn.site &lt;- 10\nx &lt;- gl(n = 2, k = n.site, labels = c('bushveld', 'agriculture'))\neps &lt;- rnorm(2*n.site, mean = 0, sd = 0.5) # normal random effect\nlambda.OD &lt;- exp(0.69 +(0.92*(as.numeric(x)-1) + eps) ) # add noise to avg count\nlambda.Poisson &lt;- exp(0.69 +(0.92*(as.numeric(x)-1)) ) # for comparison\n\nC.OD &lt;- rpois(n = 2*n.site, lambda = lambda.OD)\nC.Poisson &lt;- rpois(n = 2*n.site, lambda = lambda.Poisson)\n\n# boxplots to compare counts\npar(mfrow = c(1,2))\nggplot() +\n  geom_boxplot(aes(x = x, y = C.OD)) +\n  labs(title = 'With OD', xlab = 'Land-use', ylab = 'Hare count') +\n  ylim(0, max(C.OD))\nggplot() +\n  geom_boxplot(aes(x = x, y = C.Poisson)) +\n  labs(title = 'Without OD', xlab = 'Land-use', ylab = 'Hare count') +\n  ylim(0, max(C.OD))\n \n\n\n10.1.3 Classical analysis in R\nWe’ll start by analysing the over-dispersed data in a GLM, first without correcting, and then by correcting for over-dispersion.\nglm.fit.no.OD &lt;- glm(C.OD ~ x, family = poisson)\nglm.fit.with.OD &lt;- glm(C.OD ~ x, family = quasipoisson)\nsummary(glm.fit.no.OD)\nsummary(glm.fit.with.OD)\nanova(glm.fit.no.OD, test = \"Chisq\")\nanova(glm.fit.with.OD, test = \"F\")\nWhat we see is that the estimates between the two models are the same, but the standard errors and test statistics change considerably.\n \n\n\n10.1.4 Bayesian analysis with BUGS\nTo set up the Bayesian analysis, we’ll start with the Poisson t-test from the previous lesson and add over-dispersion to get the Poisson-lognormal model.\n# specify the model\nmodel.poisODt &lt;- nimbleCode({\n  \n  # prior\n  alpha ~ dnorm(0, sd = 30)\n  beta ~ dnorm(0, sd = 30)\n  sigma ~ dunif(0, 10)\n  \n  # likelihood\n  for (i in 1:n) {\n    C.OD[i] ~ dpois(lambda[i])\n    log(lambda[i]) &lt;- alpha + beta *x[i] + eps[i]\n    eps[i] ~ dnorm(0, sd = sigma)\n  }\n})\n\n\n# data and constants\nmy.data &lt;- list(C.OD = C.OD, x = as.numeric(x)-1)\nmy.consts &lt;- list(n = length(x))\n\n# initial values\nmy.inits &lt;- function() list(alpha = rlnorm(1), beta = rlnorm(1),\n                            sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('lambda','alpha', 'beta', 'sigma')\n\n# MCMC settings\nnc &lt;- 3\nni &lt;- 3000\nnb &lt;- 1000\nnt &lt;- 5\n\n# Start Gibbs sampling\n# start Gibbs sampler\nout1 &lt;- nimbleMCMC(code = model.poisODt,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\nTo estimate the over-dispersion effects of the added variability, we need to use longer chains. Despite this the run time should be pretty fast.",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html#zero-inflation",
    "href": "Lesson10_GLM2.html#zero-inflation",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "10.2 Zero-inflation",
    "text": "10.2 Zero-inflation\n\n10.2.1 Introduction\nWe can think of zero-inflation as a specific form of over-dispersion that is commonly found in count data. It means that we have more zeros than we would expect for a Poisson or binomial distribution. One way to interpret this is that some of the survey sites happen to fall in areas that are not habitat for scrub hares (water bodies, bare ground, tarred parking lots, etc), and so the counts there must be zero. In the suitable sites, the counts vary according to the distribution we are using. Regression models that account for these extra zeros are called zero-inflated-Poisson (ZIP) or -binomial (ZIB) models.\nA ZIP model looks like this:\n\\(w_i \\sim {\\sf Bernoulli}(\\psi_i)\\)\n\\(C_i \\sim {\\sf Poisson}(w_i \\times \\lambda_i)\\)\nInterpretation:\n\\(w_i\\): the suitability of a site (1 for yes, 0 for no); a latent or random effect, meaning we cannot observe \\(w_i\\) perfectly\n\\(\\psi_i\\): the probability that a site is suitable\n\\(\\lambda_i\\): when \\(w_i = 1\\), the expected count for site \\(i\\); when \\(w_i = 0\\), expected counts are \\(0 \\times \\lambda_i = 0\\)\n\nSet up like this, we have a set of two GLMs, one is a logistic regression that describes the suitability of a site, and one is a Poisson regression that describes the variation in counts for suitable sites. Because they are GLMs, they can be expressed as functions of covariates (not necessarily the same ones) on the scale of the link function.\nKéry (2010) makes four comments about ZIP models in the context of animal counts, which I summarise here:\n\nThe model allows for two different kinds of zeros:\n\n\nBernoulli: zeros come from surveys of unsuitable sites, where no animals are expected to be present;\nPoisson: zeros come from surveys of suitable sites which happen to have zero animals in them (i.e. part of the natural variation in a Poisson process).\n\n\nThe ZIP model is a hierarchical model that contains a binary random effect, instead of the normal random effect that we saw previously.\nSome advocate widely for the use of ZIP models for count data; however, based on ecology, they appear most suitable in situations where unknown factors affect the suitability of sites. If we have measured factors, they are usually best added as covariates to the Poisson part of the model.\nA variant of the ZIP model truncates the Poisson process so that it cannot have zero counts. In principle it might seem easier to have only one type of zero, but biologically it makes more sense for two types because of the possibility of having sites that are suitable but unoccupied.\n\n \n\n\n10.2.2 Data simulation\nWe will generate our data set based on a relatively simple scenario: different densities in bushveld and agriculture and a constant probability of suitable sites (\\(\\psi\\)) in both types of land uses.\n# set up the land use indicator variable\nn.site &lt;- 20\nx &lt;- gl(n = 2, k = n.site, labels = c(\"bushveld\", \"agriculture\"))\npsi &lt;- 0.8 # probability of a suitable site\n\n# establish which sites are suitable\nw &lt;- rbinom(n = 2*n.site, size = 1, prob = psi)\n\n# generate expected counts; assumes equal psi between land uses\nlambda &lt;- exp(0.69 +(0.92*(as.numeric(x)-1)))\n\n# combine effects of both processes and inspect\nC &lt;- rpois(n = 2*n.site, lambda = w *lambda)\ncbind(x, w, C) # all unsuitable sites have C = 0\n \n\n\n10.2.3 Classical analysis in R\nWe will fit a zero-inflated model using the function \\({\\tt zeroinfl()}\\) in the package pscl.\nlibrary(pscl)\nfm &lt;- zeroinfl(C ~ x | 1, dist = \"poisson\")\nsummary(fm)\nThe estimates are kinda-sorta close to the input values, but differences are likely because of sampling and estimation error. The “Zero-inflation model coefficient” corresponds to \\(1 - \\psi\\) from the binomial part of the ZIP model, after back-transforming from the link scale.\n \n\n\n10.2.4 Bayesian analysis with BUGS\nThe coding in NIMBLE should make it fairly clear which parts of the ZIP model are represented where. For comparison, we also calculate the logit of the zero-inflation parameter from \\(\\psi\\). We will also estimate the latent state \\(w_i\\), the suitability for hares at each site.\n# specify the model\nmodel.ZIP &lt;- nimbleCode({\n  \n  # priors\n  psi ~ dunif(0,1)\n  alpha ~ dnorm(0, sd = 30)\n  beta ~ dnorm(0, sd = 30)\n  \n  # likelihood\n  for (i in 1:n){\n    w[i] ~ dbern(psi)\n    C[i] ~ dpois(eff.lambda[i])\n    eff.lambda[i] &lt;- w[i]*lambda[i]\n    log(lambda[i]) &lt;- alpha + beta *x[i]\n  }\n  \n  # derived quantity\n  R.lpsi &lt;- logit(1 - psi)\n})\n\n# data and constants\nmy.data &lt;- list(C = C, x = as.numeric(x)-1)\nmy.consts &lt;- list(n = length(x))\n\n# Inits function\nmy.inits &lt;- function() list(alpha = rlnorm(1), beta = rlnorm(1),\n                            w = rep(1, 2*n.site))\n\n# parameters to estimate\nmy.params &lt;- c('lambda','alpha', 'beta', 'w', 'psi', 'R.lpsi')\n\n# MCMC settings (need fairly long chains)\nnc &lt;- 3\nni &lt;- 50000\nnb &lt;- 10000\nnt &lt;- 4\n\n# start Gibbs sampler\nout2 &lt;- nimbleMCMC(code = model.ZIP,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum2 &lt;- MCMCsummary(out2, round = 2))\nEstimates between the two analysis are fairly similar.",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html#offsets",
    "href": "Lesson10_GLM2.html#offsets",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "10.3 Offsets",
    "text": "10.3 Offsets\n\n10.3.1 Introduction\nIn a Poisson GLM, we assume that covariates in the model adequately describe expected counts. Sometimes, however, we have a “counting window” that is not constant. For instance, site areas might differ or duration of sampling over time might differ. To account for the variability added by this known factor, we include it as an offset, which allows us to model density (in space or time) rather than the counts directly.\nThinking about our hare data, we have counts that are distributed as a Poisson random variable: \\(C_i \\sim {\\sf Poisson}(\\lambda_i)\\). If sites have different sizes, then we have \\(C_i \\sim {\\sf Poisson}(A_i \\times \\lambda_i)\\), where \\(A_i\\) is the size of site \\(i\\). As a consequence the linear predictor becomes \\(\\log(A_i \\times \\lambda_i) = \\log(A_i) + \\log(\\lambda_i)\\), and if we want to add a covariate, we have \\(\\log(A_i \\times \\lambda_i) = \\log(A_i) + \\alpha + \\beta \\times x_i\\). Including \\(\\log(A_i)\\) as part of the intercept accounts for the variation caused by differing site area sizes.\n \n\n\n10.3.2 Data simulation\nn.site &lt;- 10\nA &lt;- runif(n = 2*n.site, 2,5)       # areas range in size from 2 to 5 km2\nx &lt;- gl(n = 2, k = n.site, labels = c('bushveld', 'agriculture'))\nlinear.predictor &lt;- log(A) + 0.69 +(0.92*(as.numeric(x)-1))\nlambda &lt;- exp(linear.predictor)\nC &lt;- rpois(n = 2*n.site, lambda = lambda) # add Poisson noise\n \n\n\n10.3.3 Classical analysis in R\nWe’ll conduct two analyses using function \\({\\tt glm()}\\), one that ignores offsets and one that includes them.\nglm.fit.no.offset &lt;- glm(C ~ x, family = poisson)\nglm.fit.with.offset &lt;- glm(C ~ x, family = poisson, offset = log(A))\nsummary(glm.fit.no.offset)\nsummary(glm.fit.with.offset)\nanova(glm.fit.with.offset, test = \"Chisq\") # LRT\nYou might notice that the residual deviance dropped considerably when we included an offset. We can treat this as a sort of correction for over-dispersion caused by variation in area size.\n \n\n\n10.3.4 Bayesian analysis with BUGS\nIt’s relatively easy to adapt previous code to give us a model in NIMBLE that includes offsets.\n# specify the model\nmodel.offs &lt;- nimbleCode({\n  \n  # priors\n  alpha ~ dnorm(0, sd = 30)\n  beta ~ dnorm(0, sd = 30)\n  \n  # likelihood\n  for (i in 1:n) {\n    C[i] ~ dpois(lambda[i])\n    log(lambda[i]) &lt;- 1 * logA[i] + alpha + beta*x[i]   # Note offset\n  }\n})\n\n# data and constants\nmy.data &lt;- list(C = C, x = as.numeric(x)-1, logA = log(A))\nmy.consts &lt;- list(n = length(x))\n\n# initial values\nmy.inits &lt;- function() list(alpha = rlnorm(1), beta = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('lambda', 'alpha', 'beta')\n\n# MCMC settings\nnc &lt;- 3\nni &lt;- 1100\nnb &lt;- 100\nnt &lt;- 2\n\n# start Gibbs sampler\nout3 &lt;- nimbleMCMC(code = model.offs,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum3 &lt;- MCMCsummary(out3, round = 2))",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html#example",
    "href": "Lesson10_GLM2.html#example",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "10.4 Example",
    "text": "10.4 Example",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html#exercises",
    "href": "Lesson10_GLM2.html#exercises",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "10.5 Exercises",
    "text": "10.5 Exercises",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson10_GLM2.html#references",
    "href": "Lesson10_GLM2.html#references",
    "title": "Lesson 10: GLM, overdispersion and offsets",
    "section": "10.6 References",
    "text": "10.6 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 10: GLM, overdispersion and offsets"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html",
    "href": "Lesson15_BinomialGLMM.html",
    "title": "Lesson 15: binomial GLMM",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 19",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html#introduction",
    "href": "Lesson15_BinomialGLMM.html#introduction",
    "title": "Lesson 15: binomial GLMM",
    "section": "15.1 Introduction",
    "text": "15.1 Introduction\nJust like with Poisson GLMMs, we can also take a binomial GLM and add random effects to the model. We will used a modified example from the crested barbet data we used previously, but instead of counting the number of pairs (which has no set upper limit), we will establish a sample of pairs and assess which are reproductively active. Imagine we are doing a survey of nest holes for crested barbets, and seeing which pairs have a successful brood. Furthermore we will incorporate the effect of precipitation. We will generate a data set covering 16 population over 10 years. Here is the random-coefficients model (without correlation) having a binomial response.\nDistribution: \\(C_i \\sim {\\sf Binomial}(p_i, N_i)\\)\nLink function: logit, \\(logit(p_i) = \\log \\left( \\frac{p_i}{1-p_i} \\right) =\\) linear predictor\nLinear predictor: \\(\\alpha_{j(i)} + \\beta_{j(i)} \\times x_i\\)\nSubmodel for parameters: \\(\\alpha_j \\sim {\\sf Normal}(\\mu_{\\alpha}, \\sigma^2_{\\alpha})\\) and \\(\\beta_j \\sim {\\sf Normal}(\\mu_{\\beta}, \\sigma^2_{\\beta})\\)\nInterpretation:\n\\(C_i\\): the number of successful pairs from \\(N_i\\) observed pairs in year \\(i\\), study area \\(j\\)\n\\(x_i\\): an explanatory variable for precipitation\n\\(\\alpha_j, \\beta_j\\): population-specific intercepts and slopes; their relationships come from two normal distributions with hyperparameters",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html#data-simulation",
    "href": "Lesson15_BinomialGLMM.html#data-simulation",
    "title": "Lesson 15: binomial GLMM",
    "section": "15.2 Data simulation",
    "text": "15.2 Data simulation\nHere we simulate a data set using the random-coefficients model; it will treat \\(\\alpha_j\\) and \\(\\beta_j\\) as independent random effects.\n# set up groups and sample sizes\nn.groups &lt;- 16\nn.years &lt;- 10\nn &lt;- n.groups * n.years\npop &lt;- gl(n = n.groups, k = n.years)\n\n# explanatory variable\nprec &lt;- runif(n, 0, 1)\n\n# numbers of studied pairs\nN &lt;- round(runif(n, 10, 50) )\n\n# design matrix\nXmat &lt;- model.matrix(~pop*prec-1-prec)\n#print(Xmat, dig = 2)       # have a look if you want\n\n# set hyperparameter input values\nintercept.mean &lt;- 1\nintercept.sd &lt;- 1\nslope.mean &lt;- -2\nslope.sd &lt;- 1\n\n# random effects\nintercept.effects&lt;-rnorm(n = n.groups, mean = intercept.mean, sd = intercept.sd)\nslope.effects &lt;- rnorm(n = n.groups, mean = slope.mean, sd = slope.sd)\nall.effects &lt;- c(intercept.effects, slope.effects) # assemble effects\n\n# calculate linear predictor, expected proportions; add binomial variation\nlin.pred &lt;- Xmat %*% all.effects\nexp.p &lt;- exp(lin.pred) / (1 + exp(lin.pred))\nC &lt;- rbinom(n = n, size = N, prob = exp.p)\n\n# let's have a look\nbarbet.df &lt;- data.frame(exp.p, prec, pop, C, N)\nggplot(data = barbet.df) +\n  geom_point(aes(x = prec, y = exp.p)) +\n  facet_wrap(~ pop, ncol = 4) +\n  labs(title = 'Expected crested barbet breeding success',\n    x = 'Year', y = 'Expected breeding success')\nggplot(data = barbet.df) +\n  geom_point(aes(x = prec, y = C/N)) +\n  facet_wrap(~ pop, ncol = 4) +\n  labs(title = 'Realised crested barbet breeding success',\n    x = 'Year', y = 'Realised breeding success')",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html#the-random-coefficients-model",
    "href": "Lesson15_BinomialGLMM.html#the-random-coefficients-model",
    "title": "Lesson 15: binomial GLMM",
    "section": "15.3 The random-coefficients model",
    "text": "15.3 The random-coefficients model\nOne assumption we could make is that all populations have the same relationship between standardised rainfall and breeding success, but at different levels. In that case, a random-intercepts model would be appropriate. For our analysis, however, we assume each population has a different (if similar) relationship to precipitation. This assumption points to the random-coefficients model.\n \n\n15.3.1 Classical analysis in R\nlibrary('lme4')\nglmm.fit &lt;- glmer(cbind(C, N-C) ~ prec + (1|pop) + (0 + prec|pop),\n                  family = binomial)\nglmm.fit\n \n\n\n15.3.2 Bayesian analysis with BUGS\n# specify the model\nmodel.binomGLMM &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:n.groups){\n    alpha[i] ~ dnorm(mu.int, sd = sigma.int)    # intercepts\n    beta[i] ~ dnorm(mu.beta, sd = sigma.beta)   # slopes\n  }\n  \n  mu.int ~ dnorm(0, sd = 30)    # hyperparameter for random intercepts\n  sigma.int ~ dunif(0, 10)\n  \n  mu.beta ~ dnorm(0, sd = 30)   # hyperparameter for random slopes\n  sigma.beta ~ dunif(0, 10)\n  \n  # Binomial likelihood\n  for (i in 1:n){\n    C[i] ~ dbin(p[i], N[i])\n    logit(p[i]) &lt;- alpha[pop[i]] + beta[pop[i]]* prec[i]\n  }\n})\n\n# data and constants\nmy.data &lt;- list(C = C, N= N, pop = as.numeric(pop), prec = prec)\nmy.consts &lt;- list(n.groups = n.groups, n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(n.groups, 0, 2),\n                            beta = rnorm(n.groups, 1, 1),\n                            mu.int = rnorm(1, 0, 1),\n                            mu.beta = rnorm(1, 0, 1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'mu.int', 'sigma.int', 'mu.beta', 'sigma.beta')\n\n# MCMC settings\nni &lt;- 2000\nnb &lt;- 500\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.binomGLMM,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\n\n# compare with input values\nintercept.mean; intercept.sd; slope.mean; slope.sd\nBoth models do a reasonable job of returning estimates close to the input values. Something you’ll likely notice is that the variances are larger in the Bayesian analysis. Remember that the classical, maximum-likelihood approach gives us an asymptotic approximation for estimates and uncertainty, whereas NIMBLE should give is exact inference incorporating all sources of uncertainty in the modelled system.",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html#example",
    "href": "Lesson15_BinomialGLMM.html#example",
    "title": "Lesson 15: binomial GLMM",
    "section": "15.5 Example",
    "text": "15.5 Example",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html#exercises",
    "href": "Lesson15_BinomialGLMM.html#exercises",
    "title": "Lesson 15: binomial GLMM",
    "section": "15.6 Exercises",
    "text": "15.6 Exercises",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson15_BinomialGLMM.html#references",
    "href": "Lesson15_BinomialGLMM.html#references",
    "title": "Lesson 15: binomial GLMM",
    "section": "15.7 References",
    "text": "15.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 15: binomial GLMM"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html",
    "href": "Lesson05_ANOVA1.html",
    "title": "Lesson 5: one-way ANOVA",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 9",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html#introduction",
    "href": "Lesson05_ANOVA1.html#introduction",
    "title": "Lesson 5: one-way ANOVA",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\nIn this lesson we will encounter the one-way ANOVA, used when there is a continuous response variable and a categorical explanatory variable with &gt;2 levels. One-way or single-factor means that we are working with one explanatory variable, but we could also consider two- or multi-factor models, main- and interaction-effects models. Here we will introduce a new way to parameterise linear models: fixed effects and random effects. In a random-effects model, we constrain the set of effects (levels) to come from some distribution (usually but not always normal). We will start with the more straight forward fixed-effects model and then proceed to random-effects models.\nImportant: If you work with ecological or environmental data, there is almost always reason to use random effects in our statistical models. These will prove to be very important tools in our statistical modelling toolbox.\nIn this lesson, we will use simulated data again and return to using a snake example. In this scenario, once again have snout–vent length (SVL) and we are interested in assessing the differences between five populations. For the fixed effects ANOVA, we will use a means parameterization:\n\\(y_i = \\alpha_{j(i)} + \\epsilon_i\\)\n\\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)\nInterpretation:\n\\(y_i\\): observed SVL of snake \\(i\\) in population \\(j\\)\n\\(\\alpha_{j(i)}\\): expected SVL of a snake in population \\(j\\)\n\\(\\epsilon_i\\): the random deviation of individual snake \\(i\\) from its population mean \\(\\alpha_{j(i)}\\); assumed to be normally distributed around zero with variance \\(\\sigma^2\\)\nBased on this model, the \\(\\alpha_{j(i)}\\)s are just unknown constants to be estimated in the model. If we add an assumption that they follow some distribution, we get a random-effects ANOVA:\n\\(y_i = \\alpha_{j(i)} + \\epsilon_i\\)\n\\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\) \\(\\alpha_{j(i)} \\sim {\\sf Normal}(\\mu, \\tau^2)\\)\nInterpretation: the main change is in terms of how we interpret \\(\\alpha_{j(i)}\\). They still represent the mean SVL for each population, but now they come from a second normal distribution with mean \\(\\mu\\) and variance \\(\\tau^2\\) (we call \\(\\mu\\) and \\(\\tau^2\\) hyperparameters).\nFixed versus random effects\n\nIf we have a particular factor of interest, and all levels of that factor are represented in a data set (e.g. sex of animal in a survival study) then the factor should be a fixed effect. If the factor is not of scientific interest, but still might affect the outcome of a study, and we have a sample of levels represented in our data set (sampling regions within a study area, where repeated measurements might occur), these would typically be defined as random effects.\nIf it is plausible that the levels of a factor represent a distribution of effects, such that one level could be replaced by another level (i.e. levels are exchangeable), such a factor would be defined as a random effect. If levels are considered unrelated or independent, then they would be defined as fixed factors.\nWe want to make inference to a wider population of levels (e.g. in the situation of sampling regions within a study area), and account for the uncertainty associated with that, then we used random effects.\nIf we selected levels for a factor in some random manner (e.g. selection of sampling regions within a study area) then we would want to account for the added uncertainty associated with the random selection of samples using random effects.\nIf we think level of a factor are not independent of each other (i.e. coming from a common distribution), then we can take advantage of the other levels to improve each individual level’s estimate. Treating them as random effects allows us to borrow information between levels. The consequence is that individual level estimates are pulled in toward the overall mean of the factor (“shrinkage”).\nKéry (2010) talks about partial pooling of effects represented by the factor. This happens because we can think of random effects as a compromise between a factor having no effect and a factor being fixed and fully independent. Essentially we can let the data tell us the degree of pooling.\nSome argue that we should use random effects even if they are independent if we think they are the result of a common stochastic process. The shrinkage of estimates should allow for a more honest accounting of variability and generate better predictions with more precision.\n\nFrom here we’ll use data simulation to generate a data set assuming fixed effects and another assuming random effects.",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html#fixed-effects-anova",
    "href": "Lesson05_ANOVA1.html#fixed-effects-anova",
    "title": "Lesson 5: one-way ANOVA",
    "section": "5.2 Fixed-effects ANOVA",
    "text": "5.2 Fixed-effects ANOVA\n\n5.2.1 Data simulation\nThe data we’ll work with will be based on SVL measurements for five simulated snake populations. The overall average will be 50 cm, and the population-specific averages will be 50, 40, 45, 55 and 60 cm. The residual standard deviation will be 3.\nngroups &lt;- 5                # no. populations\nnsample &lt;- 10               # no. snakes in each\npop.means &lt;- c(50, 40, 45, 55, 60)  # population mean SVL\nsigma &lt;- 3              # residual SD\n\nn &lt;- ngroups * nsample          # total no. data points\neps &lt;- rnorm(n, 0, sigma)       # residuals \nx &lt;- rep(1:5, rep(nsample, ngroups))    # indicator for population\nmeans &lt;- rep(pop.means, rep(nsample, ngroups))\nX &lt;- as.matrix(model.matrix(~ as.factor(x)-1)) # create design matrix\nX                   # have a look\ny &lt;- as.numeric(X %*% as.matrix(pop.means) + eps) # assemble\n                                                  # %*% matrix multiplication\n                                                  # as.numeric is ESSENTIAL\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = y)) +\n  xlab('Population') +\n  ylab('SVL')\n \n\n\n5.2.2 Classical analysis in R\nprint(anova(lm(y~as.factor(x))))\ncat(\"\\n\")\nprint(summary(lm(y~as.factor(x)))$coeff, dig = 3)\ncat(\"Sigma:         \", summary(lm(y~as.factor(x)))$sigma, \"\\n\")\nThe output shows that we’ve fit the default model with effects parameterization, giving a mean for population 1 (Intercept) and differences between that and the other populations for the other coefficients.\n\n\n5.2.3 Bayesian analysis with BUGS\nFor this model we will we will use the means parameterization, and then obtain the differences as derived quantities. Note that we use double-indexing in the BUGS code to specify the expected SVL of snake \\(i\\) based on the \\(i\\)-th value of the population index x. We also added two lines of code to test specific hypotheses about differences in SVL between particular populations of interest.\n# specify the model\nmodel.anova1 &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:5){           # implicitly define alpha as a vector\n    alpha[i] ~ dnorm(0, sd = 30)\n    }\n  sigma ~ dunif(0, 100)\n  \n  # likelihood\n  for (i in 1:n) {\n    y[i] ~ dnorm(mean[i], sd = sigma)\n    mean[i] &lt;- alpha[x[i]]\n  }\n  \n  # derived quantities\n  effe2 &lt;- alpha[2] - alpha[1]\n  effe3 &lt;- alpha[3] - alpha[1]\n  effe4 &lt;- alpha[4] - alpha[1]\n  effe5 &lt;- alpha[5] - alpha[1]\n  \n  # custom hypothesis test / define your own contrasts\n  test1 &lt;- (effe2+effe3) - (effe4+effe5) # equals zero when 2+3 = 4+5\n  test2 &lt;- effe5 - 2 * effe4        # equals zero when effe5 = 2*effe4\n})\n\n# data and constants\nmy.data &lt;- list(y = y, x = x)\nmy.consts &lt;- list(n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(5, mean = mean(y)),\n                            sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'sigma', 'effe2', 'effe3', 'effe4', 'effe5', 'test1',\n            'test2')\n\n# MCMC settings\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.anova1,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# look at output\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\nThe textbook makes a comment about quantities pD and DIC, that are provided in WinBUGS output, but not in NIMBLE output. These give measures of the effective number of parameters being estimated and of the support for the model from the data, respectively. I tend to ignore both of these numbers. You may ignore them too if you wish.\nComparing between classical and BUGS output, here is what we see:\n\nWith vague priors in the Bayesian analysis (large values for SD), the two analyses yield almost identical parameter estimates.\nIn BUGS it was easy to set up custom hypothesis tests using the derived quantities, and incorporating full error propagation from the involved quantities.\nWhile this is also possible in classical analysis with a simple model like ANOVA (e.g. via post-hoc tests), Bayesian this is equally easy for any type of parameter in any type of model, like mixed models, generalized linear models and generalize linear mixed models.",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html#random-effects-anova",
    "href": "Lesson05_ANOVA1.html#random-effects-anova",
    "title": "Lesson 5: one-way ANOVA",
    "section": "5.3 Random-effects ANOVA",
    "text": "5.3 Random-effects ANOVA\n\n5.3.1 Data simulation\nFor this data set, we will simulate values in essentially the same way, but now we assume that the SLV population means come from a normal distribution with its own hyperparameters.\nnpop &lt;- 10              # no. populations: now we choose 10 rather than 5\nnsample &lt;- 12               # no. snakes in each\nn &lt;- npop * nsample         # total no. data points\n\npop.grand.mean &lt;- 50            # grand mean SVL\npop.sd &lt;- 5             # sd of population effects about mean\npop.means &lt;- rnorm(n = npop, mean = pop.grand.mean, sd = pop.sd)\nsigma &lt;- 3              # residual SD\neps &lt;- rnorm(n, 0, sigma)       # draw residuals\n\nx &lt;- rep(1:npop, rep(nsample, npop))\nX &lt;- as.matrix(model.matrix(~ as.factor(x)-1))\ny &lt;- as.numeric(X %*% as.matrix(pop.means) + eps) # as.numeric is ESSENTIAL\n\nggplot() +\n  geom_boxplot(aes(x = as.factor(x), y = y)) +\n  geom_hline(yintercept = pop.grand.mean) +\n  xlab('Population') +\n  ylab('SVL')\nWe set up a normal distribution with its own hyperparameters ({} and {}) to describe the distribution of the separate population means. Then for each population we draw one realization and then add residual variation based on {}. As before we set up a design matrix and use matrix multiplication to generate observed values for SVL across all the populations.\n\n\n5.3.2 Classical analysis in R\nThis time we will use restricted maximum likelihood (REML) to fit a random-effects ANOVA model. To fit such a model we will need to install and call library lme4.\nlibrary('lme4')             # load lme4\npop &lt;- as.factor(x)     # define x as a factor and call it pop\nlme.fit &lt;- lmer(y ~ 1 + 1|pop, REML = TRUE)\nlme.fit                       # have a look\nranef(lme.fit)              # here are the random effects\nEach random effect value is the difference between the grand mean and each population mean.\n\n\n5.3.3 Bayesian analysis with BUGS\nNow we’ll try again using NIMBLE. We set up the random effects for the population means by specifying a common prior distribution for them.\n# specify the model\nmodel.anova2 &lt;- nimbleCode({\n  \n  # priors and some derived things\n  for (i in 1:npop){\n    pop.mean[i] ~ dnorm(mu, sd = sigma.group)   # prior for population means\n    effe[i] &lt;- pop.mean[i] - mu     # population effects as derived quant’s\n  }\n  \n  mu ~ dnorm(0, sd = 30)            # hyperprior for grand mean svl\n  sigma.group ~ dunif(0, 10)    # hyperprior for SD of population effects\n  sigma.res ~ dunif(0, 10)      # prior for residual SD\n  \n  # Likelihood\n  for (i in 1:n) {\n    y[i] ~ dnorm(mean[i], sd = sigma.res)\n    mean[i] &lt;- pop.mean[x[i]]\n  }\n})\n\n# data and constants\nmy.data &lt;- list(x = x, y = y)\nmy.consts &lt;- list(npop = npop, n = n)\n\n# initial values\nmy.inits &lt;- function() list(mu = runif(1, 0, 100), sigma.group = rlnorm(1),\n                            sigma.res = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('mu', 'pop.mean', 'effe', 'sigma.group', 'sigma.res')\n\n# MCMC settings\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampler\nout2 &lt;- nimbleMCMC(code = model.anova2,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# look at output\n(outSum2 &lt;- MCMCsummary(out2, round = 2))\nComparing between classical and BUGS output, the results are similar but not identical. Our textbook argues that lmer produces more biased estimates when there are few random-effects levels or sample size is small. Depending on the run, however (remember, with BUGS we’re always dealing with randomly-selected Markov chains), estimates for pop.sd (for example) can be closer to or farther from the true value for the classical or Bayesian approach.",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html#example",
    "href": "Lesson05_ANOVA1.html#example",
    "title": "Lesson 5: one-way ANOVA",
    "section": "5.4 Example",
    "text": "5.4 Example",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html#exercises",
    "href": "Lesson05_ANOVA1.html#exercises",
    "title": "Lesson 5: one-way ANOVA",
    "section": "5.5 Exercises",
    "text": "5.5 Exercises",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson05_ANOVA1.html#references",
    "href": "Lesson05_ANOVA1.html#references",
    "title": "Lesson 5: one-way ANOVA",
    "section": "5.6 References",
    "text": "5.6 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 5: one-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html",
    "href": "Lesson13_BinomialTtest.html",
    "title": "Lesson 13: binomial t-test",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 17",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#introduction",
    "href": "Lesson13_BinomialTtest.html#introduction",
    "title": "Lesson 13: binomial t-test",
    "section": "13.1 Introduction",
    "text": "13.1 Introduction\nIn this lesson, we shift from Poisson GLMs to binomial GLMs. They are useful for when we want to use count data to estimate binomial proportions, and the models we will use are commonly called logistic regression. The most important difference between Poisson and binomial counts is that the latter have some upper limit, and thus we are modelling bounded counts (the limit being trial size \\(N\\)). Because of this upper limit, we can express counts relative to that limit as well as proportions. Poisson counts, in contrast, lack a fixed upper limit.\nWe can think of a binomial random variable as modelling a series of coin tosses. From a total number of tosses (\\(N\\)) we might be interested in the number of heads, as well as the likelihood of getting a head on the next coin toss. That likelihood is the probability of a success: \\(Pr(heads) = Pr(success) = p\\). If we have \\(r\\) heads in a series of \\(N\\) tosses, then we write \\(r \\sim {\\sf Binomial}(N, p)\\). If we have a single toss (\\(N = 1\\)) then the associated distribution is called Bernoulli, having one parameter \\(p\\).\nFor this lesson, let’s imagine a botanist is exploring a number of nature reserves in the lowveld and is looking for two variants of the spotted aloe, Aloe greatheadii var. greatheadii and A. g. var. davyana. The botanist explores 50 sites and records whether she sees each variant or not, with the goal of assessing whether one variant is more restricted in its distribution than the other. For greatheadii she sees plants at 13 sites, and for davyana she sees plants at 29 sites. As we’ve mentioned in previous scenarios, we are assuming that plants of each variant are seen, if they are present, without error. Here is the model we will be fitting:\nDistribution: \\(C_i \\sim {\\sf Binomial}(N, p_i)\\)\nLink function: logit, \\(logit(p) = \\log \\frac{p_i}{1 - p_i}\\) = linear predictor\nLinear predictor: \\(\\alpha + \\beta \\times x_i\\)\nInterpretation:\n\\(C_i\\): the number of sites at which Aloe variant \\(i\\) is detected\n\\(x\\): indicator variable for the davyana variant\n\\(\\alpha\\): logit-scale probability of occurrence of the greatheadii variant \\(\\beta\\): difference in logit-scale probability of occurrence between greatheadii and davyana",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#data-simulation",
    "href": "Lesson13_BinomialTtest.html#data-simulation",
    "title": "Lesson 13: binomial t-test",
    "section": "13.2 Data simulation",
    "text": "13.2 Data simulation\nHere we generate data from the example described in the Introduction. Our modelled response consists of two numbers.\n# generate data\nN &lt;- 50                 # binomial total (no. coin tosses)\np.gr &lt;- 13/50               # success probability greatheadii\np.da &lt;- 29/50               # success probability davyana\n\n# add binomial noise to each\nC.gr &lt;- rbinom(1, 50, prob = p.gr)   ;   C.gr\nC.da &lt;- rbinom(1, 50, prob = p.da)   ;   C.da\nC &lt;- c(C.gr, C.da)\nvariant &lt;- factor(c(0,1), labels = c('greatheadii', 'davyana'))",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#classical-analysis-in-r",
    "href": "Lesson13_BinomialTtest.html#classical-analysis-in-r",
    "title": "Lesson 13: binomial t-test",
    "section": "13.3 Classical analysis in R",
    "text": "13.3 Classical analysis in R\nsummary(glm(cbind(C, N - C) ~ variant, family = binomial))\npredict(glm(cbind(C, N - C) ~ variant, family = binomial), type = 'response')\nOur binomial t-test indicate strong evidence of a difference in numbers of each variant detected.",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#bayesian-analysis-using-bugs",
    "href": "Lesson13_BinomialTtest.html#bayesian-analysis-using-bugs",
    "title": "Lesson 13: binomial t-test",
    "section": "13.4 Bayesian analysis using BUGS",
    "text": "13.4 Bayesian analysis using BUGS\n# specify the model\nmodel.binomT &lt;- nimbleCode({\n  \n  # priors\n  alpha ~ dnorm(0, sd = 10)\n  beta ~ dnorm(0, sd = 10)\n  \n  # likelihood\n  for (i in 1:n){\n    C[i] ~ dbin(p[i], N)        # note p before N\n    logit(p[i]) &lt;- alpha + beta *species[i]\n  }\n  \n  # derived quantities\n  Occ.great &lt;- exp(alpha) / (1 + exp(alpha))\n  Occ.davyana &lt;- exp(alpha + beta) / (1 + exp(alpha + beta))\n  Occ.Diff &lt;- Occ.davyana - Occ.great # test quantity\n})\n\n# data and constants\nmy.data &lt;- list(C = C)\nmy.consts &lt;- list(N = N, species = c(0,1), n = length(C))\n\n# initial values\nmy.inits &lt;- function() list(alpha = rlnorm(1), beta = rlnorm(1))\n\n# Parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'Occ.great', 'Occ.davyana', 'Occ.Diff')\n\n# MCMC settings\nnc &lt;- 3\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.binomT,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\nWhat we will do next is plot the posterior distributions for the two variants and the difference.\n# extract values from MCs\ngreat.samples &lt;- c(out1$chain1[,'Occ.great'],\n                   out1$chain2[,'Occ.great'],\n                   out1$chain3[,'Occ.great'])\n\ndavyana.samples &lt;- c(out1$chain1[,'Occ.davyana'],\n                     out1$chain2[,'Occ.davyana'],\n                     out1$chain3[,'Occ.davyana'])\n\ndiff.samples &lt;- c(out1$chain1[,'Occ.Diff'],\n                  out1$chain2[,'Occ.Diff'],\n                  out1$chain3[,'Occ.Diff'])\n\nggplot() +\n  xlim(0,1) +\n  geom_histogram(aes(x = great.samples), fill = 'blue') +\n  geom_vline(xintercept = outSum1$mean[3]) +\n  geom_histogram(aes(x = davyana.samples), fill = 'red') +\n  geom_vline(xintercept = outSum1$mean[2]) +\n  labs(x = 'Occurrence', y = 'Frequency') +\n  annotate(geom = 'text', x = 0.125, y = 350, label = 'greatheadii') +\n  annotate(geom = 'text', x = 0.75, y = 300, label = 'davyana')\nggplot() +\n  geom_histogram(aes(x = diff.samples), fill = 'grey') +\n  geom_vline(xintercept = 0) +\n  labs(x = 'Difference in occurence', y = 'Frequency')\nBased on the posterior distributions, the davyana variant was detected at more sites than the greatheadii variant. The difference in convincing because most or all of the mass of the posterior distribution for the differences is greater than zero.",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#example",
    "href": "Lesson13_BinomialTtest.html#example",
    "title": "Lesson 13: binomial t-test",
    "section": "13.5 Example",
    "text": "13.5 Example",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#exercises",
    "href": "Lesson13_BinomialTtest.html#exercises",
    "title": "Lesson 13: binomial t-test",
    "section": "13.6 Exercises",
    "text": "13.6 Exercises",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson13_BinomialTtest.html#references",
    "href": "Lesson13_BinomialTtest.html#references",
    "title": "Lesson 13: binomial t-test",
    "section": "13.7 References",
    "text": "13.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 13: binomial t-test"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html",
    "href": "Lesson02_LinearModels.html",
    "title": "Lesson 2: linear models",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 6",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#introduction",
    "href": "Lesson02_LinearModels.html#introduction",
    "title": "Lesson 2: linear models",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nWhen we use a statistical model, we are modelling variation in an observed response. The model we use contains a deterministic bit and a stochastic bit:\nresponse = deterministic (systematic) bit + stochastic (random) bit\nIt is the stochastic bit that makes the model statistical. To model that part, we need to choose a distribution.\n\nThe distribution we use depends on the sampling situation (i.e. how the sample units were chose and measured).\nThe response is the quantity whose variation we want to explain.\nThe statistical distributions we will focus on in this course will be normal, uniform, binomial and Poisson.\n\nWhat is a linear model?\n\nSuch models assume that the mean or expected response can be treated as the result of explanatory variables that can be added together.\nThe linear predictor in a linear model is described by the design matrix.\nThe design matrix and the observed values of the covariates together make up the deterministic part of the linear model.\nWhen we combine them, we get the expected or mean response of the linear predictor.\n\nWhy this is important: When we use standard statistics software to fit a linear model, it’s easy enough to provide the form of the model and let the software do everything else for us. It sets up the probability distributions and design matrices, and we can remain blissfully unaware of what is happening under the bonnet. This will change when we get to Bayesian analysis and the BUGS software. To set up an analysis in BUGS, we will need to understand design matrices and probability distributions for the models we want to use. This does require knowing more about how to set up statistical models, but it also gives us a lot more freedom to use custom models that might not be available in standard stats software.",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#the-stochastic-bit",
    "href": "Lesson02_LinearModels.html#the-stochastic-bit",
    "title": "Lesson 2: linear models",
    "section": "2.2 The stochastic bit",
    "text": "2.2 The stochastic bit\nWhen we fit a linear model to some data,\n\nWe are trying to describe some aspect of nature, but nature is stochastic (i.e there is an element of chance in what we observe).\nThat randomness in a statistical relationship represents the influence of factors that we haven’t measured. The reason for the effect might be present, we just might not know what it is.\nRandom variables, then, have an outcome that is only partially predictable because of that chance influence.\nHowever, a statistical distribution can do a reasonably good job of describing the combined effect of all the unmeasured factors that affect the value of a variable.\nA probability distribution assigns a probability of occurrence to each possible realisation, value or event of a random variable.\nAll possible realisations must be described so that the sum of their probabilities is 1.\nExamples of random variables:\n\nsurvival of a medical subject on an experimental drug treatment;\nnitrogen concentration in the soil at a particular sampling site;\nsex of a newborn offspring;\nmaximum temperature on a particular day;\na count of people in a pub;\nheight of a tree.\n\n\nParameters describe the form of a probability distribution.\n\nOur goal is often to estimate parameters.\nA mathematical formula containing these parameters is used to describe the distribution.\n\nTypical features of statistical distributions\n\nSome are discrete, non-negative integers (e.g. binomial, Poisson).\nSome are continuous (e.g. normal, uniform).\nCircumstances and methods of data collection usually point to an obvious choice for the probability distribution.\n\nBinomial or Poisson are used for discrete counts.\nNormal or uniform are used for continuous measurements.\nIn practice there can be some overlap; e.g. with a large sample, Poisson or binomial distributions can be approximated by the normal distribution.\n\n\n \n\n2.2.1 Normal distribution\nSampling situation: measurements that are affected by many factors whose effects are additive.\nExample: body mass, height, other linear measurements. We’ll get to this in later lessons, but in BUGS it can be used with a large variance to specify a non-informative prior distribution (i.e. to represent a quantity about which there is poor prior understanding).\nVariants: in the log-normal distribution, the effect are multiplicative; when we log-transform such values, they become normally distributed.\nGraph: bell shaped, symmetrical, unimodal, moderately long tails, can look skewed with small samples.\nThe maths: contains two parameters, the mean (\\(\\mu\\), central tendency or location) and standard deviation (\\(\\sigma\\), spread or average deviation from the mean). In BUGS, you will sometimes see precision (\\(\\tau\\)) instead of variance (\\(\\sigma^2\\)): \\(\\tau = 1/ \\sigma^2\\)\nSpecification in BUGS: \\({\\tt x \\sim dnorm(mean, sd)}\\)\nMean and standard deviation: \\[E(y) = \\mu\\] \\[SD(y) = \\sigma\\]\nHistogram of numbers drawn from a normal distribution:\nn &lt;- 100000 # sample size\nmu &lt;- 600 # average body mass of male peregrines\nsd &lt;- 30 # SD of body mass of male peregrines\n\nsample &lt;- rnorm(n = n, mean = mu, sd = sd)\nprint(sample[1:10], dig = 4)\n\nhist(sample, col = \"grey\", main = '')\n \n\n\n2.2.2 Continuous uniform distribution\nSampling situation: measurements that are all equally likely to occur, but they occur within a bounded range.\nExample: in BUGS, it can be used to specify a non-informative prior (alternative to a “flat” normal).\nVariants: discrete uniform, for when values must be integers.\nGraph: rectangular shape with some sampling variability.\nThe maths: contains two parameters: \\(a\\) is the upper limit and \\(b\\) is the lower limit.\n\nSpecification in BUGS: \\({\\tt x \\sim dunif(lower, upper)}\\)\nMean and standard deviation: \\[E(y) = (a + b)/2\\] \\[SD(y) = \\sqrt{(b-a)^2 / 12}\\]\nHistogram of numbers drawn from a uniform distribution:\nn &lt;- 100000 # sample size\na &lt;- 0 # lower limit\nb &lt;- 10 # upper limit\n\nsample &lt;- runif(n = n, min = a, max = b)\nprint(sample[1:10], dig = 4)\n\nhist(sample, col = \"grey\", main = '')\n \n\n\n2.2.3 Binomial distribution\nSampling situation: we have \\(N\\) units, and each has a probability \\(p\\) of having a certain state (e.g. heads, survive, observed, female).\nExample: number of males in a herd of size \\(N\\); it is important that \\(N\\) is potentially known (or knowable).\nVariants: the Bernoulli distribution is the binomial when \\(N = 1\\), or the binomial is the sum of \\(N\\) Bernoulli trials.\nGraph: always discrete. It can be skewed, but that depends on \\(N\\) and \\(p\\). The graph is symmetrical when \\(p = 0.5\\).\nThe maths: contains 1 or 2 parameters, the success probability \\(p\\) and the binomial total \\(N\\). Often \\(N\\) is observed and therefore not a parameter, and our aim is to estimate \\(p\\) from data. But sometimes our aim is to estimate \\(N\\) as well.\nImportant: variance is a function of the mean: \\(\\sigma^2 = N \\times p \\times (1-p)\\). There is no separate parameter for variance.\nSpecification in BUGS: \\({\\tt x \\sim dbin(p, N)}\\)\nOr the Bernoulli: \\({\\tt x \\sim dbern(p)}\\)\nMean and standard deviation: \\[E(y) = N \\times p\\] \\[SD(y) = \\sqrt{N \\times p \\times (1-p)}\\]\nHistogram of numbers drawn from a binomial distribution:\nn &lt;- 100000 # sample size\nN &lt;- 16 # number of trials\np &lt;- 0.8 # probability of a success for each trial\n\nsample &lt;- rbinom(n = n, size = N, prob = p)\nprint(sample[1:10], dig = 4)\n\nhist(sample, col = \"grey\", main = '')\n \n\n\n2.2.4 Poisson distribution\nSampling situation: units are randomly distributed in one or two dimensions, and we randomly apply a “counting window” (e.g. a plot on the ground to count plants).\nExample: number of birds in a sampling quadrat, number of customers going through a till at Woolworth’s in one hour.\nVariants: it approximates the binomial distribution when \\(N\\) is large and \\(p\\) is small. It can be approximated by a normal distribution when average count (\\(\\lambda\\)) is large (&gt;10). The negative binomial distribution is an over-dispersed version where \\(\\lambda\\) itself is a random variable with a gamma distribution (i.e. Poisson-gamma mixture).\nGraph: normal-looking, but with skew. The amount of skew depends on the value of \\(\\lambda\\).\nThe maths: It contains the single parameter \\(\\lambda\\), the mean or expected count (or sometimes density or “intensity”). The mean of the distribution is equal to the variance.\nImportant: The values from Poisson distribution are non-negative integers. There is no separate variance parameter.\nSpecification in BUGS: \\({\\tt x \\sim dpois(lambda)}\\)\n\nMean and standard deviation: \\[E(y) = \\lambda\\] \\[SD(y) = \\sqrt{\\lambda}\\]\nHistogram of numbers drawn from a Poisson distribution:\nn &lt;- 100000 # sample size\nlambda &lt;- 5 # average count per sample, density\n\nsample &lt;- rpois(n = n, lambda = lambda)\nprint(sample[1:10], dig = 4)\n\nhist(sample, col = \"grey\", main = '')",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#the-deterministic-bit",
    "href": "Lesson02_LinearModels.html#the-deterministic-bit",
    "title": "Lesson 2: linear models",
    "section": "2.3 The deterministic bit",
    "text": "2.3 The deterministic bit\nThe deterministic part of the linear model consists of the linear predictor and the design matrix. Here is a short introduction:\n\nFor each observation of the response, the design matrix indicates which effect is present (for categorical variables) and what amount of effect is present (for continuous variables).\nThere are an many columns as the fitted model has parameters.\nWhen the design matrix is multiplied with the vector of parameters, it calculates the linear predictor vector.\nThese are the mean or expected values of the response given the values of all the explanatory variables in the model (i.e. when all random variation is averaged out).\n\nFrom here we will cover how to specify design matrices for some standard statistical analyses, and we’ll cover different ways of specifying the same model (i.e. different parametrisations). To help us, we’ll use a toy dataset to work through some examples. Let’s imagine we have a sample of six snakes (Snakes? Did you say snakes?) from three populations. For each snake we also recorded region (categorical, two levels), habitat (categorical, three levels) and snout-ventral length (continuous).\nThis code in R sets up the variables.\nmass &lt;- c(6, 8, 5, 7, 9, 11)\npop &lt;- factor(c(1, 1, 2, 2, 3, 3))    # 'factor' specifies the levels of\nregion &lt;- factor(c(1, 1, 1, 1, 2, 2)) # categorical variables\nhab &lt;- factor(c(1, 2, 3, 1, 2, 3))\nsvl &lt;- c(40, 45, 39, 50, 52, 57)\n \n\n2.3.1 Model of the mean\nSetting up this model in R is easily done with\nlm(mass ~ 1)\nFormula: \\[mass_i = \\mu + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation:\n\nThe mass of each snake \\(i\\) is composed of an overall mean \\(\\mu\\) plus an individual deviation from that mean \\(\\epsilon_i\\).\nThe \\(\\epsilon_i\\)s are the residuals, and we need to specify a probability distribution for them: \\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)\n\nTo see the design matrix in R:\nmodel.matrix(mass ~ 1)\n \n\n\n2.3.2 t-test\nWe can use a t-test when we have a binary explanatory variable (\\(region\\)) and a continuous response variable (\\(mass\\)). To specify this test in R as a linear model:\nlm(mass ~ region)\nTo get the results of the test:\nsummary(lm(mass ~ region))\nFormula: \\[mass_i = \\alpha + \\beta \\times region_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation:\n\nThe mass of snake \\(i\\) is composed of a baseline mass (\\(\\alpha\\)) plus an amount that depends on the region the snake is from (\\(\\beta\\)).\nThe \\(\\epsilon_i\\)s represent the unexplained variation attributed to the individual differences between snakes. Once again, we assume a normal distribution for the residuals.\n\nA second equivalent formulation of this model: \\[mass_i \\sim {\\sf Normal}(\\alpha + \\beta \\times region_i, \\sigma^2)\\]\nThis formulation is similar to how we specify models in BUGS. The deterministic bit is \\(\\alpha + \\beta \\times region_i\\) and the stochastic bit is represented by \\({\\sf Normal}(..., \\sigma^2)\\)\nA third equivalent formulation of this model: \\[mass_i = \\mu_i + \\epsilon_i\\]\nIn this formulation, \\(mass\\) is a the sum of a systematic effect represented by expected mass \\(\\mu_i\\) and a random amount \\(\\epsilon_i\\).\n\nThe expected mass (\\(\\mu_i\\)) consists of \\(\\alpha + \\beta \\times region_i\\).\nThis is referred to as the linear predictor model, where residuals are assumed to follow a normal distribution centred on the linear predictor.\n\nHowever we specify the model, we need to understand what R does with a variable like \\(region\\) in a linear model. R converts the linear model into a design matrix with two columns.\n\nThe first column contains 1s corresponding to the intercept in the model.\nThe second column contains a dummy variable with 0s and 1s, indicating which snakes were caught in the region indicated by the column’s name.\n\nHere is what that looks like in R:\nmodel.matrix(~region)\nBy default, R uses the “treatment contrasts” parametrisation, and the estimate estimate associated with \\(region2\\) is the estimated difference between the regions.\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0\\\\\n1 & 0\\\\\n1 & 0\\\\\n1 & 0\\\\\n1 & 1\\\\\n1 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\n\nThe intercept is identical for all values of the response variable, and so is always represented by 1 (first column in the design matrix).\nTo solve for \\(\\alpha\\) and \\(\\beta\\) we need some way of dealing with the residuals \\(\\epsilon_i\\) (e.g. we could find values that minimise the sum of the squared residuals–least squares).\nTaken together, the response consists of the linear predictor plus the vector of residuals, with the linear predictor being made up of the design matrix and the parameter vector.\n\nWe can call R to fit the model for us:\nlm(mass ~ region)\nBecause we are using the default treatment contrasts parametrisation,\n\nthe intercept is the mean for \\(mass\\) for \\(region1\\);\nthe \\(region2\\) coefficient is the difference in \\(mass\\) between regions 1 and 2;\nthe model is estimating the effect of \\(region\\) on \\(mass\\) (i.e. the difference between regions);\nthis can also be called an effects parametrisation.\n\nWe can, however, reparameterize this model to give an estimate of the mean for each region:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0\\\\\n1 & 0\\\\\n1 & 0\\\\\n1 & 0\\\\\n0 & 1\\\\\n0 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nTo see this in R:\nmodel.matrix(~region-1)\nWhich parametrisation we use depends on the aims of analysis:\n\neffects: useful for testing whether there is a difference between regions (i.e. testing whether \\(\\beta = 0\\));\nmeans: to obtain a summary or estimates for the two regions;\nhowever, both models are equivalent.\n\n \n\n\n2.3.3 Simple linear regression\nIf we are interested in the relationship between two continuous variables (e.g. \\(mass\\) and \\(svl\\)) we can use simple linear regression.\nTo run a regression in R:\nlm(mass ~ svl)\nFormula: \\[mass_i = \\alpha + \\beta \\times svl_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\] Or: \\[mass_i \\sim {\\sf Normal}(\\alpha + \\beta \\times svl_i, \\sigma^2)\\] The difference between this and the t-test is that the explanatory variable \\(svl\\) contains real numbers, not just 1s and 0s.\nDesign matrix:\nmodel.matrix(~svl)\nMatrix form of the regression model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 40\\\\\n1 & 45\\\\\n1 & 39\\\\\n1 & 50\\\\\n1 & 52\\\\\n1 & 57\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nThe design matrix contains an intercept and a column with the values for the covariate \\(svl\\).\nInterpretation of parameters:\n\\(\\alpha\\): expected value of \\(mass\\) at \\(svl = 0\\)\n\\(\\beta\\): how much \\(mass\\) changes for each unit change in \\(svl\\), or the slope of the relationship\nIn R:\nlm(mass~svl)\nThe analysis output in R suggests a problem. Looking at the intercept, this is the expected value of mass for a snake having length 0. Does it seem realistic? One way to deal with this strange output is to replace \\(svl\\) with \\(svl - mean(svl)\\), so that the intercept becomes the expected mass at the average of the observed size distribution. Alternatively, we could remove the intercept. Unlike for the t-test, where doing so creates an equivalent, reparameterized model, in regression we are fitting a different model, one with the line being forced through the origin:\nmodel.matrix(~svl-1)\nlm(mass ~ svl-1)\nWe see that the slope changes. Fitting a no-intercept model makes sense only if we have a strong biological reason for fitting such a model.\n \n\n\n2.3.4 One-way analysis of variance\nIf we have a continuous response variable (\\(mass\\)) and a single categorical variable with &gt;2 levels (\\(pop\\)), we can assess the relationship between the variables with a one-way ANOVA.\nTo run an ANOVA in R:\nlm(mass ~ pop)\nFormula for effects parameterization: \\[mass_i = \\alpha + \\beta_{j(i)} \\times pop_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\] Or: \\[mass_i \\sim {\\sf Normal}(\\alpha + \\beta_{j(i)} \\times pop_i, \\sigma^2)\\]\nThis form of the model gives us a mean for \\(pop1\\) and two differences (\\(pop2 - pop1, pop3 - pop1\\)).\nFormula for means parameterization:\n\\[mass_i = \\alpha_{j(i)} \\times pop_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nHere we get a estimated mean mass (\\(\\alpha_j\\)) for snakes in each population \\(j\\).\nDesign matrices:\n# effects parameterization\nmodel.matrix(~pop)\n\n# means parameterization\nmodel.matrix(~pop-1)\nMatrix form of the effects model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0\\\\\n1 & 0 & 0\\\\\n1 & 1 & 0\\\\\n1 & 1 & 0\\\\\n1 & 0 & 1\\\\\n1 & 0 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta_2\\\\\n\\beta_3\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nMatrix form of the means model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\\\\\n0 & 0 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha_1\\\\\n\\alpha_2\\\\\n\\alpha_3\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nTo fit an ANOVA in R:\n# effect parameterization\nlm(mass ~ pop)\n\n# mean parameterization\nlm(mass ~ pop-1)\nAs mentioned before, which paramterization to choose depends on one’s objectives. Effect models are better for testing for presence of effects, means models are better for summarizing estimates and presentation.\n \n\n\n2.3.5 Two-way analysis of variance\nTwo-way or two-factor ANOVA are appropriate when we have a continuous response variable (\\(mass\\)) and two categorical explanatory variables (\\(region\\) and \\(hab\\)). In addition to effects and means parameterizations, we can also consider additive or main-effects models and multiplicative or interaction models.\nMain-effects ANOVA in R:\nlm(mass ~ region + hab)\nR automatically sets one level of each factor to zero. This is to keep from estimating more parameters than there are data to support (over-parameterization).\n \n\nEffects parameterization, main-effects model\nIn R:\nlm(mass ~ region + hab)\nFormula: \\[mass_i = \\alpha + \\beta_{j(i)} \\times region_i + \\delta_{k(i)} \\times hab_i +  \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation:\n\\(\\alpha\\): expected mass of a snake in habitat 1, region 1\n\\(\\beta_j\\): expected mean difference between snakes in regions 1 and 2\n\\(\\delta_k\\): expected mean difference between snakes in habitat 1 and those in habitats 2 and 3.\nDesign matrix:\n# effects parameterization, main-effects model\nmodel.matrix(~region + hab)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 0\\\\\n1 & 0 & 1 & 0\\\\\n1 & 0 & 0 & 1\\\\\n1 & 0 & 0 & 0\\\\\n1 & 1 & 1 & 0\\\\\n1 & 1 & 0 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta_2\\\\\n\\delta_2\\\\\n\\delta_3\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nThere is no way to specify the model in a means parameterization.\n \n\n\nEffects parameterization, interaction model\nIn R:\nlm(mass ~ region * hab)\nFormula: \\[mass_i = \\alpha + \\beta_{j(i)} \\times region_i + \\delta_{k(i)} \\times hab_i + \\gamma_{jk(i)} \\times region_i \\times hab_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation is the same as for the main-effects model, but now we have two new coefficients represented by \\(\\gamma_{jk}\\) that specifies the interaction effect between the two factors.\nDesign matrix:\n# effects parameterization, interaction model\nmodel.matrix(~region * hab)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 0 & 0 & 0\\\\\n1 & 0 & 1 & 0 & 0 & 0\\\\\n1 & 0 & 0 & 1 & 0 & 0\\\\\n1 & 0 & 0 & 0 & 0 & 0\\\\\n1 & 1 & 1 & 0 & 1 & 0\\\\\n1 & 1 & 0 & 1 & 0 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta_2\\\\\n\\delta_2\\\\\n\\delta_3\\\\\n\\gamma_{22}\\\\\n\\gamma_{33}\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\n \n\n\nMeans parameterization, interaction model\nIn R:\nlm(mass ~ region * hab-1-region-hab)\nFormula: \\[mass_i = \\alpha_{jk(i)} \\times region_i \\times hab_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation: The vector \\(\\alpha_{jk}\\) contains six elements, each one representing one combination of levels from \\(region\\) and \\(hab\\).\nDesign matrix:\n# means parameterization, interaction model\nmodel.matrix(~ region * hab-1-region-hab)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 1 & 0\\\\\n1 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha_{11}\\\\\n\\alpha_{21}\\\\\n\\alpha_{12}\\\\\n\\alpha_{22}\\\\\n\\alpha_{13}\\\\\n\\alpha_{23}\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nNotice the second column of the design matrix contains only zeros. This column represents region 2, habitat 1, from which we have no observations.\n \n\n\n\n2.3.6 Analysis of covariance\nWe specify an ANCOVA model when we have explanatory variables that are both categorical (\\(pop\\)) and continuous (\\(svl\\)). If we specify a main-effects model, the relationship between \\(mass\\) and \\(svl\\) is the same for all populations. If we specify an interaction model, the slope of the relationship differs between populations.\n \n\nEffect parameterization, additive model\nIn R:\nlm(mass ~ pop + svl)\nFormula: \\[mass_i = \\alpha + \\beta_{j(i)} \\times pop_i + \\delta \\times svl_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation:\n\\(\\alpha\\): intercept for population 1\n\\(\\beta_j\\): vector with two differences, one for \\(pop2 - pop1\\) and one for \\(pop3 - pop1\\)\n\\(\\delta\\): common slope of the relationship for all three populations\nDesign matrix:\nmodel.matrix(~pop + svl)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 40\\\\\n1 & 0 & 0 & 45\\\\\n1 & 1 & 0 & 39\\\\\n1 & 1 & 0 & 50\\\\\n1 & 0 & 1 & 52\\\\\n1 & 0 & 1 & 57\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta_1\\\\\n\\beta_2\\\\\n\\delta\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\n \n\n\nMeans parameterization, additive model\nIn R:\nlm(mass ~ pop + svl-1)\nFormula: \\[mass_i = \\alpha_{j(i)} \\times pop_i + \\delta_{j(i)} \\times svl_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation: Now \\(\\alpha_j\\) has three elements, representing the intercept of each population.\nDesign matrix:\nmodel.matrix(~pop + svl-1)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 40\\\\\n1 & 0 & 0 & 45\\\\\n0 & 1 & 0 & 39\\\\\n0 & 1 & 0 & 50\\\\\n0 & 0 & 1 & 52\\\\\n0 & 0 & 1 & 57\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha_1\\\\\n\\alpha_2\\\\\n\\alpha_3\\\\\n\\delta\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\n \n\n\nEffects parameterization, interaction model\nIn R:\nlm(mass ~ pop*svl)\nFormula: \\[mass_i = \\alpha + \\beta_{j(i)} \\times pop_i + \\delta \\times svl_i + \\gamma_{j(i)} \\times svl_i \\times pop_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation:\n\\(\\alpha\\): intercept for population 1\n\\(\\beta_j\\): vector with two differences, one for \\(pop2 - pop1\\) and one for \\(pop3 - pop1\\)\n\\(\\delta\\): common slope of the relationship for all three populations\n\\(\\gamma_{j}\\): two elements, each is a difference in slope between \\(pop2\\) and \\(pop1\\) and between \\(pop3\\) and \\(pop1\\)\nDesign matrix:\nmodel.matrix(~pop*svl)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 40 & 0 & 0\\\\\n1 & 0 & 0 & 45 & 0 & 0\\\\\n1 & 1 & 0 & 39 & 39 & 0\\\\\n1 & 1 & 0 & 50 & 50 & 0\\\\\n1 & 0 & 1 & 52 & 0 & 52\\\\\n1 & 0 & 1 & 57 & 0 & 57\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha\\\\\n\\beta_1\\\\\n\\beta_2\\\\\n\\delta\\\\\n\\gamma_1\\\\\n\\gamma_2\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\n \n\n\nMeans parameterization, interaction model\nIn R:\nlm(mass ~ pop * svl-1-svl)\nFormula: \\[mass_i = \\alpha_{j(i)} \\times pop_i + \\delta_{j(i)} \\times svl_i + \\epsilon_i\\] \\[\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\]\nInterpretation: for \\(\\gamma_{j}\\), we added the subscript \\(j\\), meaning that we estimate three slopes, one for each population.\nDesign matrix:\nmodel.matrix(~pop*svl-1-svl)\nMatrix form of the model:\n\\[\n\\left[\\begin{array}{cc}\n6\\\\\n8\\\\\n5\\\\\n7\\\\\n9\\\\\n11\n\\end{array}\\right]\n=\n\\left[\\begin{array}{cc}\n1 & 0 & 0 & 40 & 0 & 0\\\\\n1 & 0 & 0 & 45 & 0 & 0\\\\\n0 & 1 & 0 & 0 & 39 & 0\\\\\n0 & 1 & 0 & 0 & 50 & 0\\\\\n0 & 0 & 1 & 0 & 0 & 52\\\\\n0 & 0 & 1 & 0 & 0 & 57\n\\end{array}\\right]\n\\times\n\\left[\\begin{array}{cc}\n\\alpha_1\\\\\n\\alpha_2\\\\\n\\alpha_3\\\\\n\\delta_1\\\\\n\\delta_2\\\\\n\\delta_3\n\\end{array}\\right]\n+\n\\left[\\begin{array}{cc}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\epsilon_3\\\\\n\\epsilon_4\\\\\n\\epsilon_5\\\\\n\\epsilon_6\n\\end{array}\\right]\n\\]\nIf you are still confused about these different models, how to specify them and how to interpret them, go through Kéry (2010), pages 82-86, and read the text that accompanies each model. He does a good job of explaining statistical modelling in non-complicated (non-technical) language. Now let’s use R to do some analyses using these models.\n \n\n\nAdditive model, effects parameterization\n(fm &lt;- lm(mass ~ pop + svl))\nInterpretation:\nIntercept: expected mass of a snake in population 1 that has \\(svl = 0\\)\n\\(pop2, pop3\\): differences in the intercept for population 2 and 3, each compared to population 1 \\(svl\\): slope of the relationship between \\(mass\\) and \\(svl\\) for all snakes\nPlot:\nggplot() +\n  geom_point(aes(x = svl, y = mass, colour = pop)) +\n  geom_abline(intercept = fm$coefficients[1], slope = fm$coefficients[4],\n              colour = 'red') +\n  geom_abline(intercept = fm$coefficients[1] + fm$coefficients[2],\n              slope = fm$coefficients[4], colour = 'green') +\n  geom_abline(intercept = fm$coefficients[1]  + fm$coefficients[3],\n              slope = fm$coefficients[4], colour = 'blue')\nWhen we fit the additive model, we can see that we get a regression line for each population, each one with its own intercept (two are very similar), but the slope is the same across populations.\n \n\n\nInteraction model, effects parameterization\n(fm &lt;- lm(mass ~ pop * svl))\nInterpretation:\nIntercept: expected mass of a snake in population 1 that has \\(svl = 0\\)\n\\(svl\\): slope of the relationship between \\(mass\\) and \\(svl\\) for all snakes\nRemainder: intercept and slope differences between the two other populations and population 1\nPlot:\nggplot() +\n  geom_point(aes(x = svl, y = mass, colour = pop)) +\n  geom_abline(intercept = fm$coefficients[1], slope = fm$coefficients[4],\n              colour = 'red') +\n  geom_abline(intercept = fm$coefficients[1] + fm$coefficients[2],\n              slope = fm$coefficients[4] + fm$coefficients[5],\n              colour = 'green') +\n  geom_abline(intercept = fm$coefficients[1]  + fm$coefficients[3],\n              slope = fm$coefficients[4] + fm$coefficients[6],\n              colour = 'blue')\nThis time we fit the interaction model, and unlike for the additive model, each population has a line with its own intercept and its own slope. Intercepts and slopes differ between groups when using the interaction model.\nNext, just for completeness, we’ll run the means parameterization for the additive and interaction models.\n# means, additive\nlm(mass ~ pop + svl-1)\n\n# means, interaction\nlm(mass ~ pop * svl-1-svl)\nThe additive model gives estimates of individual intercept for each population and a common slope. The interaction model gives estimates for the intercepts and slopes for each population.",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#summary",
    "href": "Lesson02_LinearModels.html#summary",
    "title": "Lesson 2: linear models",
    "section": "2.4 Summary",
    "text": "2.4 Summary\nJust a reminder for why this is important: we need to have a good sense of what a statistics package is doing when it fits the different types of linear models we will encounter in this course. This is in terms of knowing which probability distributions to use, how to set up the design matrix, and how different parameterizations set the models up differently. Once we get to modelling with BUGS, we will need do these things explicitly. The different parameterizations are useful because, for a particular data set, some parameterizations will work better than others (e.g. they go faster, or don’t fail).",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#example",
    "href": "Lesson02_LinearModels.html#example",
    "title": "Lesson 2: linear models",
    "section": "2.5 Example",
    "text": "2.5 Example",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#exercises",
    "href": "Lesson02_LinearModels.html#exercises",
    "title": "Lesson 2: linear models",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson02_LinearModels.html#references",
    "href": "Lesson02_LinearModels.html#references",
    "title": "Lesson 2: linear models",
    "section": "2.7 References",
    "text": "2.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 2: linear models"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html",
    "href": "Lesson07_GeneralLinear.html",
    "title": "Lesson 7: general linear model",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 11",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#introduction",
    "href": "Lesson07_GeneralLinear.html#introduction",
    "title": "Lesson 7: general linear model",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nThe models we’ve encountered up to now (model of the mean, t-test, regression, ANOVA) are all special cases of the general linear model (not to be confused with the generalised linear model, which is still to come). The general model (also sometimes called ANCOVA) fits a continuous response variable as a function of discrete or continuous explanatory variables (often more than one of each, with interactions), plus random residual variation explained by a normal distribution.\nFor this lesson, we will return to simulating data based on snakes (Snakes? Did you say snakes?). Again we will look at length–mass relationships, and how they differ among three populations. Let’s imagine our three populations are at Madikwe (Mad), Rietvei (Rie), Sabi Sands (Sab) nature reserves. The means parametrisation of the model we will use is\n\\(y_i = \\alpha_{j(i)} + \\beta_{j(i)} \\times x_i + \\epsilon_i\\)\n\\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)\nInterpretation:\n\\(y_i\\): body mass of individual \\(i\\)\n\\(\\alpha_{j(i)}\\): intercept for population \\(j\\)\n\\(\\beta_{j(i)}\\): slope for population \\(j\\)\n\\(x_i\\): body length of individual \\(i\\)\n\\(\\epsilon_i\\): describes the combined effects of unmeasured influences on body mass of snake \\(i\\)\n \nThe effects parametrisation is\n\\(y_i = \\alpha_{Mad} + \\beta_1 \\times x_{Rei(i)} + \\beta_2 \\times x_{Sab(i)} + \\beta_3 \\times x_{body(i)} + \\beta_4 \\times x_{Rei(i)} \\times x_{body(i)} + \\beta_5 \\times x_{Sab(i)} \\times x_{body(i)}+ \\epsilon_i\\) \\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)\nInterpretation:\n\\(y_i\\) and \\(\\epsilon_i\\): as before\n\\(\\alpha_{Mad}\\): expected mass of snakes at Madikwe\n\\(\\beta_2\\) and \\(\\beta_3\\): differences in expected masses between Madikwe and Rietvlei or Sabi\n\\(\\beta_4\\) and \\(\\beta_5\\): differences in slopes between Madikwe and Rietvlei or Sabi",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#data-simulation",
    "href": "Lesson07_GeneralLinear.html#data-simulation",
    "title": "Lesson 7: general linear model",
    "section": "7.2 Data simulation",
    "text": "7.2 Data simulation\n# generate data for explanatory variables\nn.groups &lt;- 3\nn.sample &lt;- 10  \nn &lt;- n.groups * n.sample        # total no. data points\nx &lt;- rep(1:n.groups, rep(n.sample, n.groups)) # indicator for population\npop &lt;- factor(x, labels = c(\"Madikwe\", \"Rietvlei\", \"Sabi\"))\nlength &lt;- runif(n, 45, 70)      # body lengths\n\n# build design matrix and choose parameter values\nXmat &lt;- model.matrix(~ pop*length)\n# print(Xmat, dig = 2) # if you want to see it\nbeta.vec &lt;- c(-250, 150, 200, 6, -3, -4)\n\n# calculate linear predictor (expected values for mass)\n# add random variation\nlin.pred &lt;- Xmat[,] %*% beta.vec    # value of lin.predictor\neps &lt;- rnorm(n = n, mean = 0, sd = 10)  # residuals \nmass &lt;- lin.pred + eps          # response = lin.pred + residual\n\n# let's have a look\nhist(mass)\nsnakes.df &lt;- data.frame(length, mass, pop)\nggplot(data = snakes.df) +\n  geom_point(aes(x = length, y = mass, colour = pop), size = 3) +\n  labs(x = 'Body length (cm)', y = 'Body mass (g)')\nIn our data set, snakes from Madikwe have the steepest slope, followed by Rietvlei and then Sabi.",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#classical-analysis-in-r",
    "href": "Lesson07_GeneralLinear.html#classical-analysis-in-r",
    "title": "Lesson 7: general linear model",
    "section": "7.3 Classical analysis in R",
    "text": "7.3 Classical analysis in R\nIt’s relatively simple to specify the effects parametrisation model in R. We can then compare them quickly to the values we set for the data simulation to see how we did.\nsummary(lm(mass ~ pop * length))\n\nbeta.vec\ncat(\"And the residual SD was 10 \\n\")",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#bayesian-analysis-with-bugs",
    "href": "Lesson07_GeneralLinear.html#bayesian-analysis-with-bugs",
    "title": "Lesson 7: general linear model",
    "section": "7.4 Bayesian analysis with BUGS",
    "text": "7.4 Bayesian analysis with BUGS\nIn NIMBLE it’s easier to fit the means parametrisation of the model, and then use derived parameters to calculate the effects (differences) if we need them.\nI should also include a cautionary note about using standardised covariates. Well have a look at that as we go through the examples, and I’ll return to that later in the lesson.\n# specify the model\nmodel.genlin1 &lt;- nimbleCode({\n\n# priors\n  for (i in 1:n.group){\n    alpha[i] ~ dnorm(0, sd = 30)        # intercepts\n    beta[i] ~ dnorm(0, sd = 30)     # slopes\n  }\n  sigma ~ dunif(0, 100)         # residual standard deviation\n  \n  # likelihood\n  for (i in 1:n){\n    mass[i] ~ dnorm(mu[i], sd = sigma)\n    mu[i] &lt;- alpha[pop[i]] + beta[pop[i]]* length[i]\n  }\n  \n  # derived quantities\n  # define effects relative to baseline level\n  a.effe2 &lt;- alpha[2] - alpha[1]        # intercept Rietvlei vs Madikwe\n  a.effe3 &lt;- alpha[3] - alpha[1]        # intercept Sabi vs Madikwe\n  b.effe2 &lt;- beta[2] - beta[1]      # slope Rietvlei vs Madikwe\n  b.effe3 &lt;- beta[3] - beta[1]      # slope Sabi vs Madikwe\n  \n  # custom tests\n  test1 &lt;- beta[3] - beta[2]        # slope Sabi vs Rietvlei\n})\n\n# data and constants\nmy.data &lt;- list(mass = as.numeric(mass), pop = as.numeric(pop), length = length)\nmy.consts &lt;- list(n.group = max(as.numeric(pop)), n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(n.groups, 0, 2),\n                            beta = rnorm(n.groups, 1, 1), sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'sigma', 'a.effe2', 'a.effe3', 'b.effe2',\n               'b.effe3', 'test1')\n\n# MCMC settings\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout1a &lt;- nimbleMCMC(code = model.genlin1,\n                    data = my.data,\n                    constants = my.consts,\n                    inits = my.inits,\n                    monitors = my.params,\n                    thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1a &lt;- MCMCsummary(out1a, round = 2))         # look at output\nbeta.vec                # Truth in the data-generating process\nsummary(lm(mass ~ pop * length))    # the classical solution again\nWait a minute… the estimates are rather different between the classical and Bayesian analyses. What’s going on here? The small \\(\\hat{R}\\) values indicate the Markov chains converged on an estimate, so it probably isn’t that. Remember that \\({\\tt alpha[1]}\\) and \\({\\tt beta[1]}\\) in NIMBLE correspond to the intercept and the length main effect in the analysis in R and \\({\\tt a.effe2}\\), \\({\\tt a.effe3}\\), \\({\\tt b.effe2}\\), \\({\\tt b.effe3}\\) to the remaining terms of the analysis in R. So \\({\\tt lm()}\\) can produce parameter estimates similar to those used in generating the data, but not NIMBLE. Why is this?\nThe problem has to do with the scaling of the variable \\(length\\). In practice we want to standardise variables with a wide range of values so that the total spread is not too far from zero; otherwise, problems could arise. One such problem is convergence errors, but we would never suspect that looking at the values for \\(\\hat{R}\\).\nWhat’s the solution? One is to rerun the same model in a simpler form and see if we get the same output, or to compare to classical analysis. Alternatively we could plot the estimated lines on a graph with the data points. That would have demonstrated some problems.\nHere we repeat the analysis with standardised values for \\(length\\).\n# data and constants\nmy.data &lt;- list(mass = as.numeric(mass), pop = as.numeric(pop),\n                length = as.numeric(scale(length)))\nmy.consts &lt;- list(n.group = max(as.numeric(pop)), n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(n.groups, 0, 2),\n                            beta = rnorm(n.groups, 1, 1), sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'sigma', 'a.effe2', 'a.effe3', 'b.effe2',\n               'b.effe3', 'test1')\n\n# MCMC settings\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout1b &lt;- nimbleMCMC(code = model.genlin1,\n                    data = my.data,\n                    constants = my.consts,\n                    inits = my.inits,\n                    monitors = my.params,\n                    thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1b &lt;- MCMCsummary(out1b, round = 2))         # look at output\nbeta.vec                # truth in the data-generating process\n\nsummary(lm(mass ~ pop * length))    # the classical solution again\nprint(lm(mass ~ pop * as.numeric(scale(length)))$coefficients, dig = 4)\nSo we see the analyses with the standardised values for length are consistent in their parameter estimates. So in the previous analysis in NIMBLE, the Markov chains did not converge, even though the values of \\(\\hat{R}\\) said they did. As a lesson, we should always consider to transform covariate values, even if it makes interpretation and graphing more difficult later.\nMy preference is to normalise covariates like \\(length\\). That mean subtracting the mean and dividing by the standard deviation. Doing this would allow us to make the following interpretation: one standard deviation change in body length is associated with a \\(\\hat{\\beta_1}\\)-factor change in mass of snakes at Madikwe Nature Reserve. Sometimes centring alone is enough to solve the problem, in which case we could interpret relative to the original units of \\(length\\).",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#example",
    "href": "Lesson07_GeneralLinear.html#example",
    "title": "Lesson 7: general linear model",
    "section": "7.5 Example",
    "text": "7.5 Example",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#exercises",
    "href": "Lesson07_GeneralLinear.html#exercises",
    "title": "Lesson 7: general linear model",
    "section": "7.6 Exercises",
    "text": "7.6 Exercises",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson07_GeneralLinear.html#references",
    "href": "Lesson07_GeneralLinear.html#references",
    "title": "Lesson 7: general linear model",
    "section": "7.7 References",
    "text": "7.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 7: general linear model"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html",
    "href": "Lesson06_ANOVA2.html",
    "title": "Lesson 6: two-way ANOVA",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 10",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#introduction",
    "href": "Lesson06_ANOVA2.html#introduction",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nNow we include two explanatory variables in our ANOVA, allowing us to fit an additive (main-effects) model or an interaction (-effects) model. For the moment, we will stick with fixed effects (but don’t worry… more on random effects to come). It’s easy to get confused with all the different kinds of effects. Where possible I will stick with “additive” and “interaction” models when referring to them in this lesson, but the textbook loves to talk about effects, so try not to get lost.\nAdditive models: the main effects (sigh…) of factors A and B are additive, meaning meaning that the effect of the level of factor A (say \\(a_1\\)) does not depend on the level of factor B.\nInteraction models: factors A and B interact, meaning that the effect of the level of factor A is influenced by the level that it is assessed for factor B. The interaction is symmetric, meaning that we could reverse A and B, and the effect between factors would be the same interaction. However, we still consider an interaction model to be a linear model, just with an additional set of effects added to the main effects.\nThe effects parametrisation for a two-way ANOVA model is\n\\(y_i = \\alpha + \\beta_{j(i)} \\times A_i + \\delta_{k(i)} \\times B_i + \\gamma_{jk(i)} \\times A_i \\times B_i + \\epsilon_i\\)\nThis model has two factors A (with \\(j\\) levels) and B (with \\(k\\) levels). The means parameterization looks like\n\\(y_i = \\alpha_jk(i) \\times A_i \\times B_i + \\epsilon_i\\)\nFor both models, the residuals follow a normal distribution\n\\(\\epsilon_i \\sim {\\sf Normal}(0, \\sigma^2)\\)",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#data-simulation",
    "href": "Lesson06_ANOVA2.html#data-simulation",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.2 Data simulation",
    "text": "6.2 Data simulation\nOur simulated data set for this lesson will be for wing length of butterflies. For explanatory variables, we will have three elevation classes and five different populations. When we add up all the effects (differences between levels), plus their interactions, we will end up with 15 parameters to estimate, which will cost us in terms of degrees of freedom.\nWe’ll assume 12 butterflies were measured in each population, with four coming from each of the three elevation classes. We’ll set residual wing-length standard deviation to 3.\n# sample size\nn.pop &lt;- 5\nn.elev &lt;- 3\nnsample &lt;- 12\nn &lt;- n.pop * nsample\n\n# factor levels\npop &lt;- gl(n = n.pop, k = nsample, length = n)\nelev &lt;- gl(n = n.elev, k = nsample / n.elev, length = n)\n\n# effects\nbaseline &lt;- 40  # intercept\npop.effects &lt;- c(-10, -5, 5, 10) # population effects\nelev.effects &lt;- c(5, 10)    # elev effects\ninteraction.effects &lt;- c(-2, 3, 0, 4, 4, 0, 3, -2)  # interaction effects\nall.effects &lt;- c(baseline, pop.effects, elev.effects, interaction.effects)\n\nsigma &lt;- 3\neps &lt;- rnorm(n, 0, sigma)       # residuals\n\nX &lt;- as.matrix(model.matrix(~ pop*elev) ) # design matrix\n#X                  # have a look if you want\n\nwing &lt;- as.numeric(as.matrix(X) %*% as.matrix(all.effects) + eps)\n# as.numeric is ESSENTIAL\n\nboxplot(wing ~ elev*pop, col = \"grey\", xlab = \"Elevation-by-Population\",\n        ylab = \"Wing length\", main = \"Simulated data set\", las = 1,\n        ylim = c(20, 70)); abline(h = 40)   # Plot of generated data\nbutterfl.df &lt;- data.frame(wing, pop, elev)\nggplot(data = butterfl.df) +\n  geom_point(aes(x = elev, y = wing)) +\n  facet_wrap(~ pop, nrow = 2) +\n  labs(x = 'Elevation', y = 'Wing length',\n       title = 'Population-specific relationship between wing and\n       elevation class')\nggplot(data = butterfl.df) +\n  geom_point(aes(x = pop, y = wing)) +\n  facet_wrap(~ elev, nrow = 2) +\n  labs(x = 'Elevation', y = 'Wing length',\n       title = 'Elevation-specific relationship between\n       wing and population')",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#assessing-bias-and-precision-with-simulation",
    "href": "Lesson06_ANOVA2.html#assessing-bias-and-precision-with-simulation",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.3 Assessing bias and precision with simulation",
    "text": "6.3 Assessing bias and precision with simulation\nWe’ll take a brief tangent into how we can use data simulation to assess bias and precision in our estimators. First, let’s have a look at how well the analysis estimated the parameters we set in our simulation.\nlm(wing ~ pop*elev)\nall.effects\nBecause our sample size was fairly small, we wouldn’t expect there to be much similarity between the estimates and the original parameters. However, what we could do is repeat this simulation-analysis cycle many times to see how close we get on average to the true values in our simulation. This is something that can be easily done in R.\nn.iter &lt;- 1000      # desired number of iterations\nestimates &lt;- array(dim = c(n.iter, length(all.effects))) # data structure to hold results\n\nfor(i in 1:n.iter) {            # run simulation n.iter times\n   #print(i)                # optional\n   eps &lt;- rnorm(n, 0, sigma)        # residuals \n   y &lt;- as.numeric(as.matrix(X) %*% as.matrix(all.effects) + eps) # assemble data\n   fit.model &lt;- lm(y ~ pop*elev)    # break down data\n   estimates[i,] &lt;- fit.model$coefficients # keep values of coefs.\n}\n\nprint(apply(estimates, 2, mean), dig = 2)\nall.effects\nWe see that the average estimate across 1000 simulations is pretty close to the original parameters set for the simulation.",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#classical-analysis-in-r",
    "href": "Lesson06_ANOVA2.html#classical-analysis-in-r",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.4 Classical analysis in R",
    "text": "6.4 Classical analysis in R\nLet’s carry on analysing our data set in R, first using the additive model. Then well use the means parametrisation of the interaction model.\nmainfit &lt;- lm(wing ~ elev + pop)\nmainfit\n\nintfit &lt;- lm(wing ~ elev*pop-1-pop-elev)\nintfit",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#bayesian-analysis-with-bugs",
    "href": "Lesson06_ANOVA2.html#bayesian-analysis-with-bugs",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.5 Bayesian analysis with BUGS",
    "text": "6.5 Bayesian analysis with BUGS\n\n6.5.1 Additive ANOVA using NIMBLE\nWhen coding the additive model in NIMBLE, we’ll use the effects parametrisation because it’s a little easier. When doing so we need to write all the priors out instead of looping over them, because we need to set one level to zero to make the fixed-effects model identifiable.\n# specify the model\nmodel.anova2a &lt;- nimbleCode({\n  \n  # priors\n  alpha ~ dnorm(0, sd = 30)     # intercept\n  beta.pop[1] &lt;- 0          # set to zero effect of first level\n  beta.pop[2] ~ dnorm(0, sd = 30)\n  beta.pop[3] ~ dnorm(0, sd = 30)\n  beta.pop[4] ~ dnorm(0, sd = 30)\n  beta.pop[5] ~ dnorm(0, sd = 30)\n  beta.elev[1] &lt;- 0         # ditto\n  beta.elev[2] ~ dnorm(0, sd = 30)\n  beta.elev[3] ~ dnorm(0, sd = 30)\n  sigma ~ dunif(0, 100)\n  \n  # likelihood\n  for (i in 1:n){\n    wing[i] ~ dnorm(mean[i], sd = sigma)\n    mean[i] &lt;- alpha + beta.pop[pop[i]] +\n      beta.elev[elev[i]]\n  }\n})\n\n# data and constants\nmy.data &lt;- list(wing = wing, elev = as.numeric(elev), pop = as.numeric(pop))\nmy.consts &lt;- list(n = length(wing))\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(1), sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta.pop', 'beta.elev', 'sigma')\n\n# MCMC settings\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout2a &lt;- nimbleMCMC(code = model.anova2a,\n                    data = my.data,\n                    constants = my.consts,\n                    inits = my.inits,\n                    monitors = my.params,\n                    thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# look at output\n(outSum2a &lt;- MCMCsummary(out2a, round = 2))\nsummary(mainfit)\nThe estimates are very similar between the classical and Bayesian analyses. Next, we’ll try to fit an interaction model.\n \n\n\n6.5.2 Interaction ANOVA using NIMBLE\nTo make coding easier, we will use the means parametrisation, and we’ll put the parameters in an array to make it easier to organise the analysis.\n# specify the model\nmodel.anova2b &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:n.pop){\n    for(j in 1:n.elev){\n      group.mean[i,j] ~ dnorm(0, sd = 100) # this is the array\n    }\n  }\n  sigma ~ dunif(0, 100)\n  \n  # likelihood\n  for (i in 1:n){\n    wing[i] ~ dnorm(mean[i], sd = sigma)\n    mean[i] &lt;- group.mean[pop[i], elev[i]]\n  }\n})\n\n# data and constants\nmy.data &lt;- list(wing = wing, elev = as.numeric(elev), pop = as.numeric(pop),\n                n.elev = length(unique(elev)), n.pop = length(unique(pop)))\nmy.consts &lt;- list(n = length(wing))\n\n# initial values\nmy.inits &lt;- function() list(sigma = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('group.mean', 'sigma')\n\n# MCMC settings\nni &lt;- 1200\nnb &lt;- 200\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout2b &lt;- nimbleMCMC(code = model.anova2b,\n                    data = my.data,\n                    constants = my.consts,\n                    inits = my.inits,\n                    monitors = my.params,\n                    thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n# Print estimates\n(outSum2b &lt;- MCMCsummary(out2b, round = 2))\nsummary(intfit)\nAs we would hope, the results correspond fairly closely between the classical and Bayesian analyses.\n \n\n\n6.5.3 Presenting predictions\nLet’s have a look at the group estimates for the interaction model we fit in NIMBLE. These estimates are the predicted responses based on combinations of elevation class and population, with their 95% CRIs. The order corresponds to that in the box-plot earlier in the lesson.\nor &lt;- c(1,4,7,10,13,2,5,8,11,14,3,6,9,12,15)\nggplot() +\n  geom_point(aes(x = or, y = outSum2b$mean[1:15])) +\n  geom_errorbar(aes(x = or, ymin = outSum2b$`2.5%`[1:15],\n                    ymax = outSum2b$`97.5%`[1:15])) +\n  labs(x = 'Elev-by-Population', y = 'Predicted wing-length')",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#example",
    "href": "Lesson06_ANOVA2.html#example",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.6 Example",
    "text": "6.6 Example",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#exercises",
    "href": "Lesson06_ANOVA2.html#exercises",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.7 Exercises",
    "text": "6.7 Exercises",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson06_ANOVA2.html#references",
    "href": "Lesson06_ANOVA2.html#references",
    "title": "Lesson 6: two-way ANOVA",
    "section": "6.8 References",
    "text": "6.8 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 6: two-way ANOVA"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html",
    "href": "Lesson12_PoissonGLMM.html",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 16",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html#introduction",
    "href": "Lesson12_PoissonGLMM.html#introduction",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "12.1 Introduction",
    "text": "12.1 Introduction\nIn this lesson, we take the Poisson GLM from the last lesson and add in random effects. We will return to birds for simulating our data set, in this case creating survey data for crested barbets. The data will consist of 30 years of pair counts for each of 16 nature reserves and city parks. The goal will be to model population trends. We will start by working with the random-coefficients model without correlation between intercepts and slopes. The model we will work with is\nDistribution: \\(C_i \\sim {\\sf Poisson}(\\lambda_i)\\)\nLink function: log, \\(\\log(\\lambda_i) = \\log(E(C_i)) =\\) linear predictor\nLinear predictor: \\(\\log(\\lambda_i) = \\alpha_{j(i)} + \\beta_{j(i)} \\times x_i\\)\nSubmodels for random effects: \\(\\alpha_j \\sim {\\sf Normal}(\\mu_{\\alpha}, \\sigma^2_{\\alpha})\\) and \\(\\beta_j \\sim {\\sf Normal}(\\mu_{\\beta}, \\sigma^2_{\\beta})\\)\nWhat we should notice is that this is very similar to a standard GLM model, except that we have defined probability distributions for the log-linear intercept and slope. Because residual variation is included in the log-link function, we don’t include a separate distribution for the residuals. This analysis requires us to make one of two assumptions: (1) detection probability is 100%, or (2) detection probability is &lt;100% but the proportion seen is constant between years and areas.",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html#data-simulation",
    "href": "Lesson12_PoissonGLMM.html#data-simulation",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "12.2 Data simulation",
    "text": "12.2 Data simulation\nHere we simulate a data set based on the random-effects model, assuming no correlation between intercepts and slopes.\n# sample sizes and groups\nn.groups &lt;- 16\nn.years &lt;- 30\nn &lt;- n.groups * n.years\npop &lt;- gl(n = n.groups, k = n.years)\n\n# generate covariate values and standardise\noriginal.year &lt;- rep(1:n.years, n.groups)\nyear &lt;- (original.year-1)/29\n\n# design matrix\nXmat &lt;- model.matrix(~pop*year-1-year)\n#print(Xmat, dig = 2) # have a look if you want\n\n# input values for the hyperparameters\n# calculate random effects\nintercept.mean &lt;- 3\nintercept.sd &lt;- 1\nslope.mean &lt;- -2\nslope.sd &lt;- 0.6\nintercept.effects&lt;-rnorm(n = n.groups, mean = intercept.mean, sd = intercept.sd)\nslope.effects &lt;- rnorm(n = n.groups, mean = slope.mean, sd = slope.sd)\nall.effects &lt;- c(intercept.effects, slope.effects)\n\n# calculate linear predictor, expected counts and Poisson noise\nlin.pred &lt;- Xmat[,] %*% all.effects\nC &lt;- rpois(n = n, lambda = exp(lin.pred))\n\n# have a look\nggplot() +\n  geom_histogram(aes(x = C), bins = 10)\nbarbet.df &lt;- data.frame(C, original.year, pop)\nggplot(data = barbet.df) +\n  geom_point(aes(x = original.year, y = C)) +\n  facet_wrap(~ pop, ncol = 4) +\n  labs(x = 'Year', y = 'Crested barbet counts')",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html#random-coefficients-model",
    "href": "Lesson12_PoissonGLMM.html#random-coefficients-model",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "12.3 Random-coefficients model",
    "text": "12.3 Random-coefficients model\nFor analysis of real data, it might be worth fitting a random-intercepts model, and comparing to a random-coefficients model. However, in this lesson we will only work with the random-coefficients model, which assumes that each population has a separate trend. From the graph we generated, that would make sense.\n \n\n12.3.1 Classical analysis in R\nlibrary('lme4')\nglmm.fit &lt;- glmer(C ~ year + (1|pop) + (0 + year | pop), family = poisson)\nglmm.fit                # inspect results\n \n\n\n12.3.2 Bayesian analysis in BUGS\n# specify the model\nmodel.PoisGLMM &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:n.groups){\n    alpha[i] ~ dnorm(mu.int, tau.int)   # intercepts\n    beta[i] ~ dnorm(mu.beta, tau.beta)  # slopes\n  }\n  \n  mu.int ~ dnorm(0, 0.001)      # hyperparam for random intercepts\n  tau.int &lt;- 1 / (sigma.int * sigma.int)\n  sigma.int ~ dunif(0, 10)\n  \n  mu.beta ~ dnorm(0, 0.001)     # hyperparam for random slopes\n  tau.beta &lt;- 1 / (sigma.beta * sigma.beta)\n  sigma.beta ~ dunif(0, 10)\n  \n  # Poisson likelihood\n  for (i in 1:n){\n    C[i] ~ dpois(lambda[i])\n    lambda[i] &lt;- exp(alpha[pop[i]] + beta[pop[i]]* year[i])\n  }\n})\n\n# data and constants\nmy.data &lt;- list(C = C, pop = as.numeric(pop), year = year)\nmy.consts &lt;- list(n.groups = n.groups, n = n)\n\n# initial values\nmy.inits &lt;- function() list(alpha = rnorm(n.groups, 0, 2),\n                            beta = rnorm(n.groups, 0, 2),\n                            mu.int = rnorm(1, 0, 1),\n                            sigma.int = rlnorm(1),\n                            mu.beta = rnorm(1, 0, 1),\n                            sigma.beta = rlnorm(1))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'mu.int', 'sigma.int', 'mu.beta', 'sigma.beta')\n\n# MCMC settings\nni &lt;- 2000\nnb &lt;- 500\nnt &lt;- 2\nnc &lt;- 3\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.PoisGLMM,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc)\n\n(outSum1 &lt;- MCMCsummary(out1, round = 2))\n\n# Compare with input values\nintercept.mean; intercept.sd; slope.mean; slope.sd",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html#example",
    "href": "Lesson12_PoissonGLMM.html#example",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "12.5 Example",
    "text": "12.5 Example",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html#exercises",
    "href": "Lesson12_PoissonGLMM.html#exercises",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "12.6 Exercises",
    "text": "12.6 Exercises",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson12_PoissonGLMM.html#references",
    "href": "Lesson12_PoissonGLMM.html#references",
    "title": "Lesson 12: Poisson mixed-effects models",
    "section": "12.7 References",
    "text": "12.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 12: Poisson mixed-effects models"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html",
    "href": "Lesson14_BinomialANCOVA.html",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 18",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#introduction",
    "href": "Lesson14_BinomialANCOVA.html#introduction",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.1 Introduction",
    "text": "14.1 Introduction\nA binomial analysis of covariance is just a binomial GLM with continuous and categorical explanatory variables. Because of its similarity to the normal ANCOVA in lesson 7, we can take that model and modify it in a GLM framework to have a response variable that is a count determined by an underlying probability.\nIn our data simulation scenario, we will be working with two colour variants of the puff adder, one light and the other dark. The variant has been hypothesised to be related to the environment where the snakes (Snakes? Did you say snakes?) occur and the wetness of the sites. We will simulate 10 populations each in the Highveld, the Kalahari and the Lowveld. In our simulation, we can imagine that we capture a sample of snakes in each population and record the number of light and dark variants that we observe. Here is the model we will fit:\n \nDistribution: \\(C_i \\sim {\\sf Binomial}(p_i, N_i)\\)\nLink function: logit\\((p_i) = \\log \\left( \\frac{p_i}{1-p_i} \\right) =\\) linear predictor\nLinear predictor: \\(\\alpha_H + \\beta_1 \\times x_K + \\beta_2 \\times x_L + \\beta_3 \\times x_{wet} \\times + \\beta_4 \\times x_K \\times x_{wet} + \\beta_5 \\times x_L \\times x_{wet}\\)\n \nInterpretation:\n\\(C_i\\): the number of dark colour morphs in \\(N_i\\) snakes captured at each population \\(i\\)\n\\(N_i\\): the total number of snakes captured; in this case it is known rather than estimated\n\\(x_K, x_L\\): indicator variables for Kalahari and Lowveld\n\\(x_{wet}\\): an index for site wetness, ranging from 0 to 1\n\\(\\alpha_H\\): expected proportion (on logit scale) of dark snakes in the Highveld\n\\(\\beta_1, \\beta_2\\): differences in intercepts for Kalahari and Lowveld, respectively\n\\(\\beta_3, \\beta_4, \\beta_5\\): slope for Highveld between logit proportion dark snakes and wetness indicator, and the two differences in slopes for Kalahari and Lowveld",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#data-simulation",
    "href": "Lesson14_BinomialANCOVA.html#data-simulation",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.2 Data simulation",
    "text": "14.2 Data simulation\n# set up groups and sample sizes\nn.groups &lt;- 3\nn.sample &lt;- 10\nn &lt;- n.groups * n.sample\nx &lt;- rep(1:n.groups, rep(n.sample, n.groups))\npop &lt;- factor(x, labels = c('Highveld', 'Lowveld', 'Kalahari'))\n\n# explanatory variables\nwetness.H &lt;- sort(runif(n.sample, 0, 1))\nwetness.L &lt;- sort(runif(n.sample, 0, 1))\nwetness.K &lt;- sort(runif(n.sample, 0, 1))\nwetness &lt;- c(wetness.H, wetness.L, wetness.K)\n\nN &lt;- round(runif(n, 10, 50))        # get discrete Uniform values\n\n# design matrix\nXmat &lt;- model.matrix(~ pop*wetness)\n#print(Xmat, dig = 2) # have a look if you want\n\n# input values for parameters\n# intercept, L dif, K dif, wetness slope, L slope dif, K slope dif\nbeta.vec &lt;- c(-4, 1, 2, 6, 2, -5)\n\n# calculate linear predictor, expected proportions; add binomial noise\nlin.pred &lt;- Xmat[,] %*% beta.vec\nexp.p &lt;- exp(lin.pred) / (1 + exp(lin.pred))\nC &lt;- rbinom(n = n, size = N, prob = exp.p)\n\n# have a look\nggplot() +\n  geom_histogram(aes(x = C), bins = 5, colour = 'black')\nsnakes.df &lt;- data.frame(exp.p, wetness, pop, C, N)\nggplot(data = snakes.df) +\n  geom_point(aes(x = wetness, y = exp.p, colour = pop)) +\n  geom_line(aes(x = wetness, y = exp.p, colour = pop)) +\n  labs(x = 'Wetness index', y = 'Expected dark')\nggplot(data = snakes.df) +\n  geom_point(aes(x = wetness, y = C/N, colour = pop), size = 2) +\n  labs(x = 'Wetness index', y = 'Observed dark')\nThus, in our simulated data set, dark colour morphs increase substantially with wetness in the Lowveld populations, moderately in the Highveld populations, and hardly at all in the Kalahari populations.",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#classical-analysis-in-r",
    "href": "Lesson14_BinomialANCOVA.html#classical-analysis-in-r",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.3 Classical analysis in R",
    "text": "14.3 Classical analysis in R\nWe fit a binomial GLM to our data, followed by the input values for comparison.\nsummary(glm(cbind(C, N-C) ~ pop * wetness, family = binomial))\nbeta.vec # for comparison\nThe input values and estimates correspond reasonably well after allowing for sampling error and relatively small number of samples per site.",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#bayesian-analysis-in-bugs",
    "href": "Lesson14_BinomialANCOVA.html#bayesian-analysis-in-bugs",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.4 Bayesian analysis in BUGS",
    "text": "14.4 Bayesian analysis in BUGS\nIn our NIMBLE model, we add a few lines of code to calculate Pearson residuals. For a binomial response variable, these are calculated by \\((C_i-N_i p_i)/ \\sqrt{N_i p_i(1 - p_i)}\\), where \\(C_i\\) is the binomial count for population \\(i\\), and \\(N_i\\) and \\(p_i\\) are the trial size and probability of success. This gives us a raw residual divided by the standard deviation for population \\(i\\).\nFor practice, we’ll assess our model for adequate fit before diving into inference.\n# specify the model\nmodel.binomANC &lt;- nimbleCode({\n  \n  # priors\n  for (i in 1:n.groups){\n    alpha[i] ~ dnorm(0, sd = 10)        # intercepts\n    beta[i] ~ dnorm(0, sd = 10)     # slopes\n  }\n  \n  # likelihood\n  for (i in 1:n){\n    C[i] ~ dbin(p[i], N[i])\n    logit(p[i]) &lt;- alpha[pop[i]] + beta[pop[i]]*wetness[i] # lin predictor\n    \n    # fit assessments: Pearson residuals and posterior predictive check\n    Presi[i] &lt;- (C[i]-N[i]*p[i]) / sqrt(N[i]*p[i]*(1-p[i])) # Pearson resid\n    C.new[i] ~ dbin(p[i], N[i])     # create replicate data set\n    Presi.new[i] &lt;- (C.new[i]-N[i]*p[i]) / sqrt(N[i]*p[i]*(1-p[i]))\n    D[i] &lt;- Presi[i]^2 # squared Pearson residuals\n    D.new[i] &lt;- Presi.new[i]^2\n  }\n  \n  # derived quantities\n  # recover the effects relative to baseline level (no. 1)\n  a.effe2 &lt;- alpha[2] - alpha[1]        # intercept Lowveld vs Highveld\n  a.effe3 &lt;- alpha[3] - alpha[1]        # intercept Kalahari vs Highveld\n  b.effe2 &lt;- beta[2] - beta[1]      # slope Lowveld vs Highveld\n  b.effe3 &lt;- beta[3] - beta[1]      # slope Kalahari vs Highveld\n  \n  # custom tests\n  test1 &lt;- beta[3] - beta[2]        # difference slope Kalahari vs Lowveld\n  \n  # add up discrepancy measures\n  fit &lt;- sum(D[])\n  fit.new &lt;- sum(D.new[])\n})\n\n# data and constants\nmy.data &lt;- list(C = C, wetness = wetness)\nmy.consts &lt;- list(N = N, n.groups = n.groups, n = n, pop = as.numeric(pop))\n\n# initial values -- from the textbook, causes problems\n#my.inits &lt;- function() list(alpha = rlnorm(n.groups, 3, 1),\n#                            beta = rlnorm(n.groups, 2, 1)) # log-normal inits\n\n# initial values -- this one works\nmy.inits &lt;- function() list(alpha = runif(n.groups), beta = runif(n.groups))\n\n# parameters to estimate\nmy.params &lt;- c('alpha', 'beta', 'a.effe2', 'a.effe3', 'b.effe2', 'b.effe3',\n               'test1', 'Presi', 'fit', 'fit.new')\n\n# MCMC settings\nni &lt;- 1500\nnb &lt;- 500\nnt &lt;- 5\nnc &lt;- 3\n\n# start Gibbs sampling\nout1 &lt;- nimbleMCMC(code = model.binomANC,\n                   data = my.data,\n                   constants = my.consts,\n                   inits = my.inits,\n                   monitors = my.params,\n                   thin = nt, niter = ni, nburnin = nb, nchains = nc,\n                   dimensions = list(Presi = c(n), Presi.new = c(n),\n                                     D = c(n), D.new = c(n)))\n\noutSum1 &lt;- MCMCsummary(out1, round = 2)\nAn interesting problem arose when I tried to get this model to run. From the textbook we specified the initial values like this:\nmy.inits &lt;- function() list(alpha = rlnorm(n.groups, 3, 1),\n                            beta = rlnorm(n.groups, 2, 1)) # log-normal inits\nIn WinBUGS, this probably worked. But using these initial values in NIMBLE gave warnings like “logProb of data node C[20]: logProb is -Inf”, and there were problems in the output. To solve the problem I replaced those initial values with:\n# initial values -- this one works\nmy.inits &lt;- function() list(alpha = runif(n.groups), beta = runif(n.groups))\nAnd then the model worked and gave sensible output. The lesson is that we might need to make adjustments to the way we generate initial values to keep from getting strange errors. I solved this by finding a solution on the internet. On to goodness-of-fit:\n# sequential plots of residuals\nggplot() +\n  geom_point(aes(x = 1:n, y = outSum1$mean[1:30])) +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Order of observation', y = 'Pearson residual')\n# residual versus wetness covariate\nggplot() +\n  geom_point(aes(x = wetness, y = outSum1$mean[1:30])) +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Wetness index', y = 'Pearson residual')\n## posterior predictive check\n# extract 'fit' and 'fit.new' from MCs\nfit.samples &lt;- c(out1$chain1[,'fit'], out1$chain2[,'fit'], out1$chain3[,'fit'])\nfitnew.samples &lt;- c(out1$chain1[,'fit.new'], out1$chain2[,'fit.new'],\n                    out1$chain3[,'fit.new'])\n\n# plot discrepancy values\nggplot() +\n  geom_point(aes(x = fit.samples, y = fitnew.samples)) +\n  geom_abline(intercept = 0, slope = 1) +\n  labs(x = 'Discrepancy actual data', y = 'Discrepancy ideal data')\n# calculate Bayesian p-value\nmean(fitnew.samples &gt; fit.samples)\nThe residuals look fine. The p-value tells us that we have adequate fit of our simulated data to the model. Now let’s look at the estimates.\n# Bayesian analysis\nMCMCsummary(out1, ISB = F, exact = T, round = 2,\n            params = c('alpha[1]', 'a.effe2', 'a.effe3', 'beta[1]', 'b.effe2',\n                       'b.effe3'))\nbeta.vec # input values, for comparison\n\n# compare to the classical analysis\nprint(glm(cbind(C, N-C) ~ pop * wetness, family = binomial)$coef, dig = 4)\nInterestingly, when I ran this model using the iterations specified in the textbook example, I sometimes got high (&gt;1.1) Rhat values (chains not converging). That tells us that longer chains might be necessary to get stable posterior distributions. To check this, let’s have a look at the trace and density plots of the Markov chains.\nMCMCtrace(out1, ISB = F, exact = T, pdf = F,\n          params = c('alpha[1]', 'a.effe2', 'a.effe3', 'beta[1]', 'b.effe2',\n                     'b.effe3'))\nThe traceplots appear stable, but I would say they don’t look “grassy” enough. The density plots look good (fairly symmetrical, unimodal, no obvious truncation). From here I would probably rerun with a larger number of iterations, maybe \\(10 \\times\\). Try this and see if the Markov chains improve.\nDespite high Rhat values, however, the two analysis methods return to us estimates that are similar to the input values. This and the adequate goodness-of-fit give us confidence that the models are correctly specified.",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#example",
    "href": "Lesson14_BinomialANCOVA.html#example",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.5 Example",
    "text": "14.5 Example",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#exercises",
    "href": "Lesson14_BinomialANCOVA.html#exercises",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.6 Exercises",
    "text": "14.6 Exercises",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "Lesson14_BinomialANCOVA.html#references",
    "href": "Lesson14_BinomialANCOVA.html#references",
    "title": "Lesson 14: binomial ANCOVA",
    "section": "14.7 References",
    "text": "14.7 References\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK.",
    "crumbs": [
      "Lesson 14: binomial ANCOVA"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied statistical modelling in the environmental sciences",
    "section": "",
    "text": "Readings: Kéry (2010) chapter 1\nThe aim of this course is to develop abilities in applied statistical modelling using approaches that draw from classical, likelihood-based statistics (i.e. methods you would likely have covered in previous stats courses), and to use that as a foundation to introduce Bayesian statistics. If you have no prior experience with Bayesian statistics, it might sound a little daunting, but I think you’ll find that building models within a Bayesian framework will give you a better understanding of how statistical models work more generally. This should, in turn, make you better at applying models to data and using them to make inferences. Nonetheless, there is utility in using both classical and Bayesian approaches, and we will move back and forth between them as we cover each model."
  },
  {
    "objectID": "index.html#why-use-a-bayesian-approach-at-all",
    "href": "index.html#why-use-a-bayesian-approach-at-all",
    "title": "Applied statistical modelling in the environmental sciences",
    "section": "Why use a Bayesian approach at all?",
    "text": "Why use a Bayesian approach at all?\nThere are a number of reasons why it might be preferable to use Bayesian analysis over classical:\n\nModels that are appropriate for socio-ecological systems are too complex for most standard classical models. Bayesian approaches have much more flexibility and a facility to develop hierarchical models more suitable for complex systems–but don’t worry, we will start simple and build up the complexity of the models we use in this course.\nClassical inference assumes large samples (\\(n \\to \\infty\\)) to produce unbiased estimates. For finite samples, and particularly small samples, estimates are approximate. This is not the case in Bayesian inference, which is exact regardless of the sample size.\nComputing uncertainty for functions of random variables can be difficult. For example, if you have two population estimates with standard errors (SE), \\(N_1\\) and \\(N_2\\) and you want to calculate a rate of change \\(\\lambda = N_2 / N_1\\), you would have to approximate the SE for \\(\\lambda\\) using something like the delta method. With Markov chain Monte Carlo (MCMC) in Bayesian analysis you could calculate a posterior distribution for the derived quantity and use that distribution to get a point estimate, SEs or 95% credible intervals (CRIs) in a relatively straight-forward way.\nIf you’ve heard about Bayesian analysis at all, it has almost certainly been with respect to priors and updating prior beliefs with new information. Bayesian methods provide a formal approach for doing this.\nThe Bayesian view of probability is intuitive. Unlike the classical perspective, which views it as the frequency with which something occurs, Bayesian view it in the more human way as a degree of belief that something will happen. Within a statistical context, Bayesian probability is about the probability that a parameter has a certain value. This compares to the slightly backward classical view that focuses on the probability of obtaining a particular data set given some hypothesized value for a parameter (i.e. parameters are treated as fixed).\nOnce you get to know it, Bayesian is conceptually simple; it is based on three axioms. Classical statistics is more of a patchwork of theory, ad hoc amendments with internal contradictions.\n\nWe will cover common statistical models that are frequently used in the environmental sciences and other disciplines: linear, generalized linear, linear mixed, and generalized linear mixed models. Mathematically all these models are related to each other, differing in what kind of response variables we use and whether we are representing one or more than one random process.\nThe analyses we cover will for the most part be using the classical and the Bayesian approach. Thus we will be learning both R coding and modelling in the BUGS language, learning how they both work and what they tell us about our data. Often we will fit the same model using both approaches so we can compare between them and learn as we go. The reasons for doing this:\n\nIt should give us confidence when output from the two approaches yield similar results.\nIt should also help to clarify mysterious Bayesian analysis when we can compare it to a more conventional analysis."
  },
  {
    "objectID": "index.html#using-simulated-data",
    "href": "index.html#using-simulated-data",
    "title": "Applied statistical modelling in the environmental sciences",
    "section": "Using simulated data",
    "text": "Using simulated data\nAlthough we will make use of example data sets to learn how to apply statistical models, we will also use data simulation. This serves several key purposes:\n\nWe can compare estimated parameters to those used to simulate data; this allows us to see whether our analysis reproduces estimates close to the true values. This is something we cannot do with real data.\nWe can check our coding for mistakes. Correct specification of the model and the programming should return estimates close to the true values.\nRepeated generation of simulated data sets will give us a sense of sampling variation, something that is more difficult to grasp from a single real data set.\nWe can assess bias and precision of estimates, the sample size necessary to get a desired level of precision, and goodness-of-fit of models to data by comparing simulated and observed data sets.\nWe can assess effects of violations of assumptions on estimation.\nWe can use simulated data to judge how well we understand the model we’re using."
  },
  {
    "objectID": "index.html#a-note-on-software",
    "href": "index.html#a-note-on-software",
    "title": "Applied statistical modelling in the environmental sciences",
    "section": "A note on software",
    "text": "A note on software\nWe will be using R for this course, and the course assumes some basic competency with this software. If you are new to R, do the following online tutorial:\nhttps://intro2r.com/\nDo all sections up to chapter 6 (or more if you’re keen). Chapter 1 will show you how to install R and RStudio. We will use both.\nIf you used R at some time in the past, and it’s still sitting somewhere on your computer, uninstall R and RStudio, and reinstall the latest versions.\nTo do Bayesian analysis, we will use an R library/package called NIMBLE. To use this package, we will need to install a C++ compiler. Instructions can be found here:\nhttps://r-nimble.org/html_manual/cha-installing-nimble.html\nOnce the compiler is installed, you should be able to install NIMBLE from within RStudio. Instructions for installing packages are here:\nhttps://intro2r.com/packages.html\nAnother library we will make regular use of is tidyverse, and in particular, ggplot2 as a part of the tidyverse suite of libraries. ggplot2 has a much more intuitive way of making graphs than in base R (which is what the textbook uses). If you need extra help getting up to speed with ggplot2, there there are plenty of tutorials online. Here is one:\nhttps://ggplot2.tidyverse.org/articles/ggplot2.html\nLet me know if you encounter problems."
  },
  {
    "objectID": "index.html#a-note-on-the-textbook",
    "href": "index.html#a-note-on-the-textbook",
    "title": "Applied statistical modelling in the environmental sciences",
    "section": "A note on the textbook",
    "text": "A note on the textbook\nThis course is based in large part on the material in Kéry (2010). It is important to note, however, that the world of Bayesian analysis has progressed since this book was published. The concepts and most of the programming are still valid, but Kéry (2010) used WinBUGS for running his Bayesian analyses, whereas we will use NIMBLE. Although much of the code is very similar, there will be some differences. When in doubt, use the code that I have prepared for these course notes. If questions or confusion arise, please check with me."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Applied statistical modelling in the environmental sciences",
    "section": "References",
    "text": "References\nIf you want to learn more about NIMBLE, I recommend these online resources:\nhttps://oliviergimenez.github.io/nimble-workshop/\nhttps://oliviergimenez.github.io/banana-book/intronimble.html\nKéry M (2010) Introduction to WinBUGS for ecologists. Academic Press, London, UK."
  }
]